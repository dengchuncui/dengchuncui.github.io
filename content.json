{"meta":{"title":"邓纯粹的blog","subtitle":"不定时更新技术博客","description":"java 大数据 多线程 计算存储分离 中间件 高可用","author":"dengchuncui","url":"https://dengchuncui.github.io","root":"/"},"pages":[{"title":"分类","date":"2021-05-03T09:46:58.000Z","updated":"2021-05-03T10:03:46.595Z","comments":false,"path":"categories/index.html","permalink":"https://dengchuncui.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-05-03T09:27:39.000Z","updated":"2021-05-03T10:03:17.995Z","comments":false,"path":"tags/index.html","permalink":"https://dengchuncui.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"10分钟了解SimbaFs解决hadoop存算分离问题","slug":"10分钟了解SimbaFs解决hadoop存算分离问题","date":"2021-04-12T14:41:14.000Z","updated":"2021-05-04T06:10:23.709Z","comments":true,"path":"2021/04/12/10分钟了解SimbaFs解决hadoop存算分离问题/","link":"","permalink":"https://dengchuncui.github.io/2021/04/12/10%E5%88%86%E9%92%9F%E4%BA%86%E8%A7%A3SimbaFs%E8%A7%A3%E5%86%B3hadoop%E5%AD%98%E7%AE%97%E5%88%86%E7%A6%BB%E9%97%AE%E9%A2%98/","excerpt":"一、前言&nbsp;&nbsp;&nbsp;&nbsp;众所周知传统的 Apache Hadoop 的架构存储和计算是耦合在一起的, HDFS 作为其分布式文件系统也面临一些问题。如: 存储空间或者计算资源不足两者只能同时扩容、扩容效率低、额外增加成本、灵活性差等。本文会大家回顾Hadoop的传统架构来分析上述问题以及Hadoop实现存算分离的方案和DataSimba的对于Hadoop存算分离的最佳实践。 二、Hadoop分布式文件系统(HDFS)的架构和问题&nbsp;&nbsp;&nbsp;&nbsp;HDFS的架构:","text":"一、前言&nbsp;&nbsp;&nbsp;&nbsp;众所周知传统的 Apache Hadoop 的架构存储和计算是耦合在一起的, HDFS 作为其分布式文件系统也面临一些问题。如: 存储空间或者计算资源不足两者只能同时扩容、扩容效率低、额外增加成本、灵活性差等。本文会大家回顾Hadoop的传统架构来分析上述问题以及Hadoop实现存算分离的方案和DataSimba的对于Hadoop存算分离的最佳实践。 二、Hadoop分布式文件系统(HDFS)的架构和问题&nbsp;&nbsp;&nbsp;&nbsp;HDFS的架构: &nbsp;&nbsp;&nbsp;&nbsp;HDFS采用master/slave架构。一个HDFS集群是由一个Namenode和一定数目的Datanodes组成。 Namenode: Namenode是一个中心服务器，负责管理文件系统的名字空间(namespace)以及客户端对文件的访问 Namenode执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体Datanode节点的映射。 Datanode: 集群中的Datanode一般是一个节点一个，负责管理它所在节点上的存储。 HDFS暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组Datanode上。 Datanode负责处理文件系统客户端的读写请求。在Namenode的统一调度下进行数据块的创建、删除和复制。 Client: 用户操作HDFS文件进行创建、删除、移动或重命名操作的客户端。 &nbsp;&nbsp;&nbsp;&nbsp;Hadoop分布式文件系统的设计目标: 适合运行在通用硬件和廉价机器(commodity hardware)上的分布式文件系统 机器的硬件错误常的态化,让HDFS具有错误检测和快速、自动的恢复能力是最核心的架构目标 数据批处理关键的在于数据访问的高吞吐量,而POSIX标准设置的很多硬性约束对HDFS应用系统不是必需的。为了提高数据的吞吐量，在一些关键方面对POSIX的语义做了一些修改。 HDFS应用一次写入多次读取”的文件访问简单一致性模型 移动计算的思想: 进行一次请求计算数据距离越近就越高效,在海量数据处理下hadoop将计算逻辑移动到存储节点。 数据切分成块、数据复制副本(容错)、数据副本分布策略、机架感知、副本选择等特性来保证hdfs可靠性和提高性能的关键。 Datanode节点周期性地向Namenode发送心跳信号、负载均衡策略、HDFS文件内容的校验和(checksum)检查保证HDFS的健壮性和可靠性。 &nbsp;&nbsp;&nbsp;&nbsp;Hadoop分布式文件系统的问题: 计算存储耦合: 上面说过HDFS采用移动计算的思想,计算的时候只需要将计算代码推送到存储节点上,即可在存储节点上完成数据本地化计算，Hadoop 中的集群存储节点也是计算节点。所以当存储空间或计算资源不足时，只能同时对两者进行扩容。如果用户的计算需求远远大于存储需求,此时扩容集群会造成存储的浪费,相反则计算资源被浪费。 扩容问题: 集群节点增多,扩容成本增加,风险增加 HDFS性能问题: HDFS NameNode的全局锁虽然简化了锁模型降低了复杂度,但是全局锁最大的缺点就是容易产生性能瓶颈 HDFS成本问题: 在HDFS文件系统中典型文件大小一般都在G字节至T字节,由于HDFS的副本特性一份文件至少会存储3份,这些额外的空间会带来存储成本额外的提高 针对上面一些问题,现在Hadoop采用存算分离的架构的方案趋势越来越明显 三、Hadoop 实现存算分离方案: 方案一: Hadoop 兼容的文件系统: &nbsp;&nbsp;&nbsp;&nbsp;上图是Hadoop3.X 目前兼容的文件系统,支持aws s3、腾讯云 cos、阿里云 oss存储,可以看到用户在上传数据时候,需要调用对应云服务厂商的sdk进行数据的写入。下载文件也是一样的原理。不过为什么现在可以使用这种方式实现Hadoop的计算存储分离呢？ &nbsp;&nbsp;&nbsp;&nbsp;举一个例子日常生活中遇到的经历：家里带宽自从升级到100mpbs，从来不保存电影，要看直接下载，基本几分钟就好了。这在几年前不可想象。 带宽的速度，特别是机房内带宽的速度，已经从1000mps、2000mps、10000mps，甚至100000mpbs。但是磁盘的速度基本没有太大的变化。因为硬件的变化，带来了软件架构的变化。 &nbsp;&nbsp;&nbsp;&nbsp;虽然方案一可以实现计算存储分离,但是基本架构上还是存在问题:虽然带宽增加,但是如果Hadoop集群机房和对应的对象存储机房距离较远,网络抖动等原因加大了传输失败的几率,还有比如判断一个目录需要多次的refs请求才能完成操作,多次请求会对性能造成影响。 方案二: 云原生的Hadoop文件系统 SimbaFs: &nbsp;&nbsp;&nbsp;&nbsp;上图是SimbaFs的架构,SimbaFsClient是一个java开发的jar包,兼容Hadoop文件系统，按照Hadoop FileSystem API规范来实现。主要实现了Hadoop FileSystem的list、delete、rename、mkdir等接口，而InputStream和OutputStream主要实现了对文件读写优化相的等实现(预读、缓存读、异步写、批量写、文件压缩)。SimbaFs client通过JNI (Java Native Interface) 技术转换为本地simbafs.so的调用实现相关方法,完成文件的上传/下载操作。 压测情况: &nbsp;&nbsp;&nbsp;&nbsp;由于对于读做了预读和缓存操作,对于写的操作通过异步写和批量写的优化所以SimbaFs的性能也是非常优秀的。我们在发行版本为cdh5的集群, hdfs版本为2.6做了测试。使用3台阿里云4核14g的ecs做压力测试,对象存储选择的是oss,并且保证集群节点和oss在同一机房。下面是关于create_write、open_read、rename、delete 等操作的压测结果。 可以看到SimbaFs的性能在open_read、create_write、rename是远好于HDFS的 四、小节&nbsp;&nbsp;&nbsp;&nbsp;本文先回顾了传统Hadoop分布式文件系统的架构和问题,以及实现Hadoop存算分离的方案,并详细介绍了DataSimba对存算分离的SimbaFs的实现原理和压测情况。最后真心希望本文对你所有帮助。","categories":[{"name":"大数据","slug":"大数据","permalink":"https://dengchuncui.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://dengchuncui.github.io/tags/Hadoop/"},{"name":"计算存储分离","slug":"计算存储分离","permalink":"https://dengchuncui.github.io/tags/%E8%AE%A1%E7%AE%97%E5%AD%98%E5%82%A8%E5%88%86%E7%A6%BB/"},{"name":"云原生","slug":"云原生","permalink":"https://dengchuncui.github.io/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"}]},{"title":"数据同步 DATAX 工作原理及源码解读","slug":"【数据同步】DATAX 工作原理及源码解读","date":"2020-10-22T13:12:44.000Z","updated":"2021-05-04T06:22:47.104Z","comments":true,"path":"2020/10/22/【数据同步】DATAX 工作原理及源码解读/","link":"","permalink":"https://dengchuncui.github.io/2020/10/22/%E3%80%90%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E3%80%91DATAX%20%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/","excerpt":"DataX 工作原理及源码解读背景：&nbsp;&nbsp; 最近在工作中接触到阿里的数据同步工具datax,通过其实现了一些数据源的数据同步功能,虽然在官方文档中了解其工作原理,但是还是对其如何实现的可扩展的架构,和不同数据源之间导入导出的原理比较感兴趣,查看网上的一些介绍并没有深入源码，所以闲暇时间查看了datax的主流程代码,对此做了一下总结。","text":"DataX 工作原理及源码解读背景：&nbsp;&nbsp; 最近在工作中接触到阿里的数据同步工具datax,通过其实现了一些数据源的数据同步功能,虽然在官方文档中了解其工作原理,但是还是对其如何实现的可扩展的架构,和不同数据源之间导入导出的原理比较感兴趣,查看网上的一些介绍并没有深入源码，所以闲暇时间查看了datax的主流程代码,对此做了一下总结。 概述:&nbsp;&nbsp;该文章主要内容如下: datax 介绍 datax 工作原理 datax 如何本地调试 datax 源码分析 总结一、datax 介绍&nbsp;&nbsp; github: datax&nbsp;&nbsp; DataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。具体内容可以查看官方文档这里就不做多描述。二、datax 工作原理1. Datax核心架构图&nbsp;&nbsp; 上图为官方文档的架构图,主要氛围3个大的模块分别为job、task、taskgroup job：datax 每执行一个同步任务则为一个job task：datax 底层原理是将一个job,根据切分策略拆分为多个task来进行并发执行,task是datax的最小执行单位。例：我要同步mysql一个表的数据到hive,我的切分规则为id,假设一张表有1w条记录，我的并发设置为5,则最总会生成25个task(并发数量*5),每个任务同步400条数据。 taskgroup：datax内部Scheduler模块会将拆分的task进行重组合生成taskgroup,创建对应数量的线程池进行任务数据的同步,同步顺序 Reader—&gt;Channel—&gt;Writer 2. Datax框架执行顺序在看源码之前需要了解datax的执行顺序才能深入理解其工作原理,下面内容是在官方复制的,已经理解其内容的同学可以选择跳过。上图中，黄色表示Job部分的执行阶段，蓝色表示Task部分的执行阶段，绿色表示框架执行阶段。 三、datax 如何本地调试 下载datax源码到本地1git clone https:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;DataX.git idea 打开项目进行编译 1clean package assembly:assembly -Dmaven.test.skip&#x3D;true 3. 获取启动参数&nbsp;&nbsp; datax的启动命令为 1datax.py xxx.json datax.py脚本在 /datax-core/bin/datax.py中我们用编译器打开执行python脚本,代码如下 12345678910111213141516171819if __name__ &#x3D;&#x3D; &quot;__main__&quot;: printCopyright() parser &#x3D; getOptionParser() options, args &#x3D; parser.parse_args(sys.argv[1:]) if options.reader is not None and options.writer is not None: generateJobConfigTemplate(options.reader,options.writer) sys.exit(RET_STATE[&#39;OK&#39;]) if len(args) !&#x3D; 1: parser.print_help() sys.exit(RET_STATE[&#39;FAIL&#39;]) &#x2F;&#x2F; 这里生成执行脚本 startCommand &#x3D; buildStartCommand(options, args) # print startCommand child_process &#x3D; subprocess.Popen(startCommand, shell&#x3D;True) register_signal() (stdout, stderr) &#x3D; child_process.communicate() sys.exit(child_process.returncode) 进行debug调试,获取执行datax的系统参数如下： 1java -server -Xms1g -Xmx1g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;core&#x2F;src&#x2F;main&#x2F;log -Xms1g -Xmx1g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;core&#x2F;src&#x2F;main&#x2F;log -Dloglevel&#x3D;info -Dfile.encoding&#x3D;UTF-8 -Dlogback.statusListenerClass&#x3D;ch.qos.logback.core.status.NopStatusListener -Djava.security.egd&#x3D;file:&#x2F;&#x2F;&#x2F;dev&#x2F;urandom -Ddatax.home&#x3D;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;core&#x2F;src&#x2F;main -Dlogback.configurationFile&#x3D;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;core&#x2F;src&#x2F;main&#x2F;conf&#x2F;logback.xml -classpath &#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;core&#x2F;src&#x2F;main&#x2F;lib&#x2F;*:. -Dlog.file.name&#x3D;grui_temp_datax_json com.alibaba.datax.core.Engine -mode standalone -jobid -1 -job &#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;datax.json 通过启动参数我们可以知道，datax的主方法在com.alibaba.datax.core.Engine,中并且有3个参数分别是model、jobid、job我们把pyhton 脚本生成的命令加工一下放到idea中进行调试。加工后的命令如下： 1-Xms1g -Xmx1g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;target&#x2F;datax&#x2F;datax&#x2F;log -Dloglevel&#x3D;info -Dfile.encoding&#x3D;UTF-8 -Ddatax.home&#x3D;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;target&#x2F;datax&#x2F;datax -Dlogback.configurationFile&#x3D;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;target&#x2F;datax&#x2F;datax&#x2F;conf&#x2F;logback.xml -Dlog.file.name&#x3D;s_datax_job_job_json datax 源码分析 这次例子是将mysql中的数据同步到本地所以我的datax json文件内容如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&#123; &quot;job&quot;: &#123; &quot;content&quot;: [ &#123; &quot;reader&quot;: &#123; &quot;name&quot;: &quot;mysqlreader&quot;, &quot;parameter&quot;: &#123; &quot;username&quot;: &quot;xxx&quot;, &quot;password&quot;: &quot;xxx&quot;, &quot;column&quot;: [ &quot;xxx&quot;, &quot;xxx&quot;, &quot;xxx&quot;, &quot;xxx&quot;, &quot;xxx&quot;, &quot;xxx&quot; ], &quot;splitPk&quot;: &quot;id&quot;, &quot;connection&quot;: [ &#123; &quot;table&quot;: [ &quot;xxxx&quot; ], &quot;jdbcUrl&quot;: [ &quot;xxxxx&quot; ] &#125; ] &#125; &#125;, &quot;writer&quot;: &#123; &quot;name&quot;: &quot;txtfilewriter&quot;, &quot;parameter&quot;: &#123; &quot;path&quot;: &quot;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;data&quot;, &quot;fileName&quot;: &quot;test&quot;, &quot;writeMode&quot;: &quot;truncate&quot;, &quot;dateFormat&quot;: &quot;yyyy-MM-dd&quot;, &quot;fieldDelimiter&quot;: &quot;,&quot; &#125; &#125; &#125; ], &quot;setting&quot;: &#123; &quot;speed&quot;: &#123; &quot;channel&quot;: 5 &#125; &#125; &#125;&#125; 代码debug 直接执行 Engine.entry(args) 方法,具体逻辑如下 进行main方法参数提取 将datax的json文件转化成Configuration对象(json文件的内容直接通过这个对象可以获取到对应的属性) 对datax json文件做了校验 执行engine.start(configuration)方法 start()方法 12&#x2F;&#x2F; 该方法对datax 的json配置文件做了一些填充ColumnCast.bind(allConf); 该方法对datax 的json配置文件做了一些填充,填充内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&#123; &quot;common&quot;:&#123; &quot;column&quot;:&#123; &quot;dateFormat&quot;:&quot;yyyy-MM-dd&quot;, &quot;datetimeFormat&quot;:&quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;encoding&quot;:&quot;utf-8&quot;, &quot;extraFormats&quot;:[ &quot;yyyyMMdd&quot; ], &quot;timeFormat&quot;:&quot;HH:mm:ss&quot;, &quot;timeZone&quot;:&quot;GMT+8&quot; &#125; &#125;, &quot;core&quot;:&#123; &quot;container&quot;:&#123; &quot;job&quot;:&#123; &quot;id&quot;:-1, &quot;reportInterval&quot;:10000 &#125;, &quot;taskGroup&quot;:&#123; &quot;channel&quot;:5 &#125;, &quot;trace&quot;:&#123; &quot;enable&quot;:&quot;false&quot; &#125; &#125;, &quot;dataXServer&quot;:&#123; &quot;address&quot;:&quot;http:&#x2F;&#x2F;localhost:7001&#x2F;api&quot;, &quot;reportDataxLog&quot;:false, &quot;reportPerfLog&quot;:false, &quot;timeout&quot;:10000 &#125;, &quot;statistics&quot;:&#123; &quot;collector&quot;:&#123; &quot;plugin&quot;:&#123; &quot;maxDirtyNumber&quot;:10, &quot;taskClass&quot;:&quot;com.alibaba.datax.core.statistics.plugin.task.StdoutPluginCollector&quot; &#125; &#125; &#125;, &quot;transport&quot;:&#123; &quot;channel&quot;:&#123; &quot;byteCapacity&quot;:67108864, &quot;capacity&quot;:512, &quot;class&quot;:&quot;com.alibaba.datax.core.transport.channel.memory.MemoryChannel&quot;, &quot;flowControlInterval&quot;:20, &quot;speed&quot;:&#123; &quot;byte&quot;:-1, &quot;record&quot;:-1 &#125; &#125;, &quot;exchanger&quot;:&#123; &quot;bufferSize&quot;:32, &quot;class&quot;:&quot;com.alibaba.datax.core.plugin.BufferedRecordExchanger&quot; &#125; &#125; &#125;, &quot;entry&quot;:&#123; &quot;jvm&quot;:&quot;-Xms1G -Xmx1G&quot; &#125;, &quot;job&quot;:Object&#123;...&#125;, &quot;plugin&quot;:&#123; &quot;reader&quot;:&#123; &quot;mysqlreader&quot;:&#123; &quot;class&quot;:&quot;com.alibaba.datax.plugin.reader.mysqlreader.MysqlReader&quot;, &quot;description&quot;:&quot;useScene: prod. mechanism: Jdbc connection using the database, execute select sql, retrieve data from the ResultSet. warn: The more you know about the database, the less problems you encounter.&quot;, &quot;developer&quot;:&quot;alibaba&quot;, &quot;name&quot;:&quot;mysqlreader&quot;, &quot;path&quot;:&quot;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;target&#x2F;datax&#x2F;datax&#x2F;plugin&#x2F;reader&#x2F;mysqlreader&quot; &#125; &#125;, &quot;writer&quot;:&#123; &quot;txtfilewriter&quot;:&#123; &quot;class&quot;:&quot;com.alibaba.datax.plugin.writer.txtfilewriter.TxtFileWriter&quot;, &quot;description&quot;:&quot;useScene: test. mechanism: use datax framework to transport data to txt file. warn: The more you know about the data, the less problems you encounter.&quot;, &quot;developer&quot;:&quot;alibaba&quot;, &quot;name&quot;:&quot;txtfilewriter&quot;, &quot;path&quot;:&quot;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;DataX&#x2F;target&#x2F;datax&#x2F;datax&#x2F;plugin&#x2F;writer&#x2F;txtfilewriter&quot; &#125; &#125; &#125;&#125; 可以看到我们原来配置的json内容只是整个json的job部分，其他内容都是由 ColumnCast.bind(allConf)方法补充的。后面调用了 下面的方法(伪代码) 12AbstractContainer container &#x3D; new JobContainer(allConf);container.start(); JobContainer start()方法 可以看到datax调用方法顺序如下： 123456789101112131415&#x2F;&#x2F; 前置处理 this.preHandle(); &#x2F;&#x2F; 初始化 this.init(); &#x2F;&#x2F; 准备方法 this.prepare(); &#x2F;&#x2F; 任务切分 this.split(); &#x2F;&#x2F; 执行调度 this.schedule(); &#x2F;&#x2F; ... this.post(); &#x2F;&#x2F; ... this.postHandle(); this.invokeHooks(); 其中核心的方法为 this.init() 、this.split()、 this.schedule() 本次重点只看这几个方法init()方法initJobReader方法通过方法将mysql插件的类家在到jvm中 1LoadUtil.loadJobPlugin(PluginType.READER,this.readerPluginName) 提取Configuration 对象参数的部分插入到 jobReader 的pluginJobConf 属性中,具体内容如下 1234567891011121314151617181920212223242526272829303132&#x2F;&#x2F; pluginJobConf&#123; &quot;column&quot;:[ &quot;id&quot;, &quot;project_id&quot;, &quot;alarm_time&quot;, &quot;job_id&quot;, &quot;job_name&quot;, &quot;receiver&quot; ], &quot;connection&quot;:[ &#123; &quot;jdbcUrl&quot;:[ &quot;xxxx&quot; ], &quot;table&quot;:[ &quot;xxxxx&quot; ] &#125; ], &quot;password&quot;:&quot;xxxxx&quot;, &quot;splitPk&quot;:&quot;id&quot;, &quot;username&quot;:&quot;xxxx&quot;&#125;&#x2F;&#x2F; peerPluginJobConf&#123; &quot;dateFormat&quot;:&quot;yyyy-MM-dd&quot;, &quot;fieldDelimiter&quot;:&quot;,&quot;, &quot;fileName&quot;:&quot;test&quot;, &quot;path&quot;:&quot;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;data&quot;, &quot;writeMode&quot;:&quot;truncate&quot;&#125; 最终执行jobReader.init(); mysql插件的init方法进行初始化。initJobWriter()逻辑类似这里就不查看了split()方法split方法是reader和writer最细粒度的切分,writer的切分结果要参照reader的切分结果达到切分后数目相等，才能满足1：1的通道模型 split 方法分为3部分 拆分reader 根据reader的拆分结果拆分writer 将reader 和 writer的拆分结果 合并到Configuration对象中具体的拆分情况，感兴趣的同学可以看一下对应插件的源码下面是我当前任务拆分后,我之前配置的json内容变成什么样子了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394&#123; &quot;common&quot;:Object&#123;...&#125;, &quot;core&quot;:&#123; &quot;container&quot;:&#123; &quot;job&quot;:Object&#123;...&#125;, &quot;taskGroup&quot;:&#123; &quot;channel&quot;:5 &#125;, &quot;trace&quot;:Object&#123;...&#125; &#125;, &quot;dataXServer&quot;:Object&#123;...&#125;, &quot;statistics&quot;:&#123; &quot;collector&quot;:Object&#123;...&#125; &#125;, &quot;transport&quot;:Object&#123;...&#125; &#125;, &quot;entry&quot;:&#123; &quot;jvm&quot;:&quot;-Xms1G -Xmx1G&quot; &#125;, &quot;job&quot;:&#123; &quot;content&quot;:[ Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, &#123; &quot;reader&quot;:&#123; &quot;name&quot;:&quot;mysqlreader&quot;, &quot;parameter&quot;:&#123; &quot;column&quot;:&quot;id,xx,xx,job_id,xxx,xxx&quot;, &quot;columnList&quot;:[ &quot;xxx&quot;, &quot;xxx&quot;, &quot;xxx&quot;, &quot;xxx&quot;, &quot;xxxx&quot;, &quot;xxxx&quot; ], &quot;fetchSize&quot;:-2147483648, &quot;isTableMode&quot;:true, &quot;jdbcUrl&quot;:&quot;jxxxxxx&quot;, &quot;loadBalanceResourceMark&quot;:&quot;xxxx&quot;, &quot;password&quot;:&quot;xxxxxx&quot;, &quot;pkType&quot;:&quot;pkTypeLong&quot;, &quot;querySql&quot;:&quot;select xxx,xxxx,xxxx,xxxx,xxxx,xxxx from xxxx where (2977 &lt;&#x3D; id AND id &lt; 3473) &quot;, &quot;splitPk&quot;:&quot;id&quot;, &quot;table&quot;:&quot;xxxx&quot;, &quot;tableNumber&quot;:1, &quot;username&quot;:&quot;xxxx&quot; &#125; &#125;, &quot;taskId&quot;:6, &quot;writer&quot;:&#123; &quot;name&quot;:&quot;txtfilewriter&quot;, &quot;parameter&quot;:&#123; &quot;dateFormat&quot;:&quot;yyyy-MM-dd&quot;, &quot;encoding&quot;:&quot;UTF-8&quot;, &quot;fieldDelimiter&quot;:&quot;,&quot;, &quot;fileName&quot;:&quot;test__ad112b06_6dd1_4708_a608_890fbf55f7b1&quot;, &quot;path&quot;:&quot;&#x2F;Users&#x2F;dengmingrui&#x2F;temp&#x2F;data&quot;, &quot;writeMode&quot;:&quot;truncate&quot; &#125; &#125; &#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125;, Object&#123;...&#125; ], &quot;setting&quot;:&#123; &quot;speed&quot;:&#123; &quot;channel&quot;:5 &#125; &#125; &#125;, &quot;plugin&quot;:Object&#123;...&#125;&#125; 可以看到job.content数组下面多了很多小job,这里每个小job就是我们一开始说的task,每一个task 都有对应reader和writer的数据源信息。datax这里把json完的很6schedule()方法 &nbsp;&nbsp;一开始我们说过了schedule 是把拆分的结果合并到一个taskgroup中,最终执行最终调用startAllTaskGroup()发放执行taskgroup的任务 最终线程执行的方法在TaskGroupContainer累的run()方法中,这里逻辑太长了就不截图了datax 将任务最终放入到队列中，后面有一个死循环一直从队列中获取任务最终调用 taskExecutor.doStart();方法执行到真正单个task执行的逻辑 doStart() 方法 先开启写线程，再开启读线程 readerThread 和 writerThread 是什么时候初始化的呢？答：是在 new TaskExecutor()的时候, 最终读取的还是json中的plugin配置最终执行的run方法是在ReaderRunner和WriterRunner这2个类对应的run()方法 reader 和 writer 之间是如何通信的呢？答： Record 对象，reader 插件在读取之后，将对应的数据封装到Record对象,存储在集合中,writer 读取对应的集合数据在执行写入到目标数据源。下面是mysql插件的逻辑最终写入的方法在BufferedRecordExchanger类的sendToWriter方法读取的场景在WriterRunner类的run()方法 1taskWriter.startWrite(recordReceiver); 到这里我们就把task 读写场景的核心逻辑看完了 总结&nbsp;&nbsp;本次查看了datax的源码,对datax有了更生层次的理解,datax的插件架构还是学习到了，并且整个任务全程用json对应的Configuration类贯穿整个链路非常使得代码非常灵活。datax对任务的拆分设计和精准的速度控制逻辑的设计后面也有借鉴的地方，类加载器的使用非常巧，代码整体上还是写的非常易懂的看起来并不吃力。其实datax的架构和执行逻辑文档上写的还是很清楚的，如果感兴趣的话可以快速看一下源码的。","categories":[{"name":"大数据","slug":"大数据","permalink":"https://dengchuncui.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"源码","slug":"源码","permalink":"https://dengchuncui.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"datax","slug":"datax","permalink":"https://dengchuncui.github.io/tags/datax/"},{"name":"数据同步","slug":"数据同步","permalink":"https://dengchuncui.github.io/tags/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"},{"name":"大数据","slug":"大数据","permalink":"https://dengchuncui.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"项目规范 对于服务异常和错误码规范的总结","slug":"项目规范 对于服务异常和错误码规范的总结","date":"2020-10-02T06:05:48.000Z","updated":"2021-05-04T06:24:49.148Z","comments":true,"path":"2020/10/02/项目规范 对于服务异常和错误码规范的总结/","link":"","permalink":"https://dengchuncui.github.io/2020/10/02/%E9%A1%B9%E7%9B%AE%E8%A7%84%E8%8C%83%20%E5%AF%B9%E4%BA%8E%E6%9C%8D%E5%8A%A1%E5%BC%82%E5%B8%B8%E5%92%8C%E9%94%99%E8%AF%AF%E7%A0%81%E8%A7%84%E8%8C%83%E7%9A%84%E6%80%BB%E7%BB%93/","excerpt":"服务异常和错误码规范背景&nbsp;&nbsp;目前公司的服务端返回的异常不规范,导致接口各个场景返回的异常不统一,使得项目不好维护。并且代码看起来不优雅,目前公司项目遇到了国际化的问题,服务端的异常也需要做出相关调整。所以对服务端的异常错误码制定一个规范。 思考 需要制定那些异常？ 错误码如何设计？如何做到可读性、可维护、灵活可控？ 新的异常规范,如何设计才会对当前项目侵入性小？","text":"服务异常和错误码规范背景&nbsp;&nbsp;目前公司的服务端返回的异常不规范,导致接口各个场景返回的异常不统一,使得项目不好维护。并且代码看起来不优雅,目前公司项目遇到了国际化的问题,服务端的异常也需要做出相关调整。所以对服务端的异常错误码制定一个规范。 思考 需要制定那些异常？ 错误码如何设计？如何做到可读性、可维护、灵活可控？ 新的异常规范,如何设计才会对当前项目侵入性小？ 异常分类&nbsp;&nbsp;根据之前的工作经验,异常分为两个大分类,未知异常、已知异常,结合这两个分类对异常进行拆分,直到拆分到不能拆分为止。拆分结果如下： 异常拆分一定要结合整体服务业务,有些公司服务的异常可能其他公司永远都用不上。比如电商的项目有些异常场景可能做crm系统的永远用不上。所以不要盲目借鉴。 异常介绍 未知异常未知异常指的是服务端不可感知和控制的异常,如引入的jar包中抛出的异常,或者数据库链接异常,或者代码bug出现的空指针异常和badsql,这些异常是服务端可能出现的情况,上面列举的几个场景也确实是服务器异常,所以针对这种情况,服务端接口返回的http状态码是500 无需将相关异常栈信息返回,增加代码安全性。 这里指的安全性是比如写了一个badsql 如果把异常栈抛出去则会导致数据表泄漏 已知异常已知异常是服务端知道可能出现异常的场景,目前拆分为前置异常、外部异常、自定义异常,对于这些异常http状态码是200,并且可以返回响应的错误信息,具体描述如下 前置异常：指的是代码还没有到真正业务逻辑前抛出的异常,比如参数校验失败异常、用户没有权限异常、token过期异常、未找到资源异常 等等， 外部异常：指的是因为外部因素导致的接口异常而非正常业务逻辑错误或者数据错误导致的,比如第三方服务商异常、接口被限流、接口重复请求 自定义异常：指的是程序员自己抛出来的异常，这种异常是因为代码在相关业务逻辑中，不满足业务条件并且必须手动抛出的异常，比如:子表记录找不到对应父表的记录,这种正常逻辑是不可能存在场景,是需要手动抛出异常进行排查的并且这种问题你也没办法兼容。或者举行一个秒杀活动，在活动未开始之前就有请求到服务端了，这是不现实的情况,并且于这种场景需要以来服务端的响应作出对应的展示文案，所有服务端需要自定义相关的异常返回,前段解析相关的错误码作出相关的文案展示。对于这种异常称作自定义异常。 错误码的设计 错误码的作用 程序员根据错误码能够快速定位问题 通过不同的错误码可以区分出是什么原因导致的问题(传参错误，没有权限，服务异常) 明确清晰的展示错误信息，方便程序员快速定位问题 错误码的定义 数字类型error_code标识 长度可控,节省传输带宽 可读性差,需要相关文档 数字范围分段,表示不通分类,不同业务的异常 字符串类型的error_code标识 长度稍长 可读性高,见名知意 123456&#123; &#39;error_code&#39;:401, &#39;error_str_code&#39;:&#39;UnAuthorized&#39;, &#39;error_msg&#39;:&#39;user un Authorized: user_id:&#123;xxx&#125;&#39;, &#39;error_reason&#39;:&#39;用户未授权&#39;&#125; 错误码枚举伪代码 1234567891011121314151617181920212223242526272829303132333435363738public interface ErrorCodeInterface &#123; Integer getErrorCode(); String getStrErrorCode(); String getMsg(); String getReason();&#125;@AllArgsConstructorpublic enum xxxxErrorCode implements ErrorCodeInterface&#123; ENCODE_SDK_LICENSE_OVERDUE(1001, &quot;ActivityNotStarted&quot;, &quot;Current Activity not started&quot;,&quot;当前活动暂未开始&quot;), Integer errorCode; String strErrorCode; String msg; String reason ; @Override public Integer getErrorCode() &#123; return errorCode; &#125; @Override public String getMsg() &#123; return msg; &#125; @Override public String getStrMsg() &#123; return strMsg; &#125; @Override public String getReason() &#123; return reason; &#125;&#125; 异常伪代码 123456789101112131415161718192021222324252627public class DataSimbaRuntimeException extends RuntimeException &#123; private String reason; public DataSimbaRuntimeException(String msg) &#123; this(msg, &quot;&quot;); &#125; public DataSimbaRuntimeException(String msg, Throwable cause) &#123; this(msg, &quot;&quot;, cause); &#125; public DataSimbaRuntimeException(String msg, String reason) &#123; super(msg); this.reason &#x3D; reason; &#125; public DataSimbaRuntimeException(String msg, String reason, Throwable cause) &#123; super(msg, cause); this.reason &#x3D; reason; &#125; public String getReason() &#123; return this.reason &#x3D;&#x3D; null ? &quot;&quot; : this.reason; &#125;&#125; 12345678910111213141516171819202122&#x2F;*** * 请求校验异常 *&#x2F;public class RequestValidateException extends DataSimbaRuntimeException &#123; public RequestValidateException(String msg, Throwable cause) &#123; super(msg, cause); &#125; public RequestValidateException(String msg) &#123; super(msg); &#125; public RequestValidateException(String msg, String reason) &#123; super(msg, reason); &#125; public RequestValidateException(String msg, String reason, Throwable cause) &#123; super(msg, reason, cause); &#125;&#125; 12345678910111213141516171819202122&#x2F;*** * 没有权限异常 *&#x2F;public class UnAuthorizedException extends DataSimbaRuntimeException &#123; public UnAuthorizedException(String msg, Throwable cause) &#123; super(msg, cause); &#125; public UnAuthorizedException(String msg) &#123; super(msg); &#125; public UnAuthorizedException(String msg, String reason) &#123; super(msg, reason); &#125; public UnAuthorizedException(String msg, String reason, Throwable cause) &#123; super(msg, reason, cause); &#125;&#125; 如何应用和error_code 约定 比如 请求参数不对,需要抛出请求参数异常则1throw new RequestValidateException(&quot;lack of user id&quot;,&quot;lack of user id&quot;) 在服务端创建异常拦截器,对异常统一处理 对于未知异常,http状态码是500, 已知异常和自定义异常http状态码为200 前置异常 error_code :400～499 外部异常 error_code :600～699 自定义异常 不同的自定义error_code长度从都从1000开始,如果业务需要可以跳号到2000或者到3000开始等等总结&nbsp;&nbsp;&nbsp;&nbsp;本次整理服务端异常和错误码的规范结合了之前工作的经验,回想了开发以来出现的异常场景,之前工作中虽然熟知如何合理的抛出异常,但是大前提是一个团队需要对异常作出响应的规范，如果没有规范每个人都抛出自己方式的异常，对于前端展示和问题排查都是非常不友好的，并且不够灵活，比如目前工作中遇到的国际化问题，必须服务端的异常非常准确,后面做国际化才能非常简单。","categories":[{"name":"项目规范","slug":"项目规范","permalink":"https://dengchuncui.github.io/categories/%E9%A1%B9%E7%9B%AE%E8%A7%84%E8%8C%83/"}],"tags":[{"name":"项目规范","slug":"项目规范","permalink":"https://dengchuncui.github.io/tags/%E9%A1%B9%E7%9B%AE%E8%A7%84%E8%8C%83/"},{"name":"错误码","slug":"错误码","permalink":"https://dengchuncui.github.io/tags/%E9%94%99%E8%AF%AF%E7%A0%81/"}]},{"title":"集合类框架 hashmap 源码详解","slug":" java【集合类框架】 hashmap 源码详解","date":"2020-09-22T04:05:48.000Z","updated":"2021-05-04T06:18:23.249Z","comments":true,"path":"2020/09/22/ java【集合类框架】 hashmap 源码详解/","link":"","permalink":"https://dengchuncui.github.io/2020/09/22/%20java%E3%80%90%E9%9B%86%E5%90%88%E7%B1%BB%E6%A1%86%E6%9E%B6%E3%80%91%20hashmap%20%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/","excerpt":"介绍HashMap 可能是面试的时候必问的题目了，面试官为什么都偏爱拿这个问应聘者？因为 HashMap 它的设计结构和原理比较有意思，它既可以考初学者对 Java 集合的了解又可以深度的发现应聘者的数据结构功底。","text":"介绍HashMap 可能是面试的时候必问的题目了，面试官为什么都偏爱拿这个问应聘者？因为 HashMap 它的设计结构和原理比较有意思，它既可以考初学者对 Java 集合的了解又可以深度的发现应聘者的数据结构功底。 Java 7 中 HashMapHashMap 是最简单的，一来我们非常熟悉，二来就是它不支持并发操作，所以源码也非常简单。d 首先，我们用下面这张图来介绍 HashMap 的结构。 大方向上，HashMap 里面是一个数组，然后数组中每个元素是一个单向链表。为什么是这种的结构，这涉及到数据结构方面的知识了。 HashMap的数据结构数据结构中有数组和链表来实现对数据的存储，但这两者基本上是两个极端。 数组数组存储区间是连续的，占用内存严重，故空间复杂的很大。但数组的二分查找时间复杂度小，为O(1)；数组的特点是：寻址容易，插入和删除困难； 链表链表存储区间离散，占用内存比较宽松，故空间复杂度很小，但时间复杂度很大，为O(N)。链表的特点是：寻址困难，插入和删除容易。 哈希表那么我们能不能综合两者的特性，做出一种寻址容易，插入删除也容易的数据结构？答案是肯定的，这就是我们要提起的哈希表。哈希表（(Hash table）既满足了数据的查找方便，同时不占用太多的内容空间，使用也十分方便。 哈希表有多种不同的实现方法，我接下来解释的是最常用的一种方法—— 拉链法，我们可以理解为“链表的数组”，如图： 从上图我们可以发现哈希表是由数组+链表组成的，一个长度为16的数组中，每个数组中元素存储的是一个链表的头结点。 那么这些元素是按照什么样的规则存储到数组中呢。一般情况我们首先想到的就是元素的 key 的哈希值对数组长度取模得到 ( hash(key)%(length -1) )，这样一来，元素的分布相对来说是比较均匀的。但是，“模”运算的消耗还是比较大的，能不能找一种更快速，消耗更小的方式那？java中是这样做的： 123static int indexFor(int h, int length) &#123; return h &amp; (length-1); &#125; 我们知道每个数据对象的hash对应唯一一个值，但是一个hash值不一定对应唯一的数据对象。如果两个不同对象的 hashCode 相同，此情况即称为哈希冲突。比如上述HashMap中，12%16=12，28%16=12，108%16=12，140%16=12。所以12、28、108以及140都存储在数组下标为12的位置，然后依次放在数组中该位置的链表上。 注意：对于那些 hash 冲突的数据，最新(最后) Put 的值放在链表的头部，为什么这样做呢？因为我们程序设计中认为最新放进去的值它的使用率会更高些，放在链表头比较容易查询获取到。 HashMap 里面实现一个静态内部类 Entry，Entry 包含四个属性：key，value，hash值和用于单向链表的 next。从属性key，value我们就能很明显的看出来 Entry 就是 HashMap 键值对实现的一个基础 bean，我们上面说到 HashMap的基础就是一个线性数组，这个数组就是 Entry[]，Map 里面的内容都保存在 Entry[] 里面。上图中，每个绿色的实体是嵌套类 Entry 的实例。 capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。loadFactor：负载因子，默认为0.75。threshold：扩容的阈值，等于 capacity * loadFactor。注意问题： 1、扩容的数组的长度为什么保持 2^n？其实这是为了保证通过hash方式获取下标的时候分布均匀。数组长度为2的n次幂的时候，不同的key 算得得 index 相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了。 2、为什么负载因子的值默认为 0.75？加载因子是表示Hash表中元素的填满的程度。 加载因子越大，填满的元素越多，空间利用率越高，但冲突的机会加大了。反之,加载因子越小，填满的元素越少，冲突的机会减小，但空间浪费多了。冲突的机会越大，则查找的成本越高。反之，查找的成本越小。 因此,必须在 “冲突的机会”与”空间利用率”之间寻找一种平衡与折衷。 put 过程分析还是比较简单的，跟着代码走一遍吧。 1234567891011121314151617181920212223242526272829public V put(K key, V value) &#123; &#x2F;&#x2F; 当插入第一个元素的时候，需要先初始化数组大小 if (table &#x3D;&#x3D; EMPTY_TABLE) &#123; inflateTable(threshold); &#125; &#x2F;&#x2F; 如果 key 为 null，感兴趣的可以往里看，最终会将这个 entry 放到 table[0] 中 if (key &#x3D;&#x3D; null) return putForNullKey(value); &#x2F;&#x2F; 1. 求 key 的 hash 值 int hash &#x3D; hash(key); &#x2F;&#x2F; 2. 找到对应的数组下标 int i &#x3D; indexFor(hash, table.length); &#x2F;&#x2F; 3. 遍历一下对应下标处的链表，看是否有重复的 key 已经存在， &#x2F;&#x2F; 如果有，直接覆盖，put 方法返回旧值就结束了 for (Entry&lt;K,V&gt; e &#x3D; table[i]; e !&#x3D; null; e &#x3D; e.next) &#123; Object k; if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || key.equals(k))) &#123; V oldValue &#x3D; e.value; e.value &#x3D; value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; &#x2F;&#x2F; 4. 不存在重复的 key，将此 entry 添加到链表中，细节后面说 addEntry(hash, key, value, i); return null;&#125; 数组初始化（inflateTable）在第一个元素插入 HashMap 的时候做一次数组的初始化，就是先确定初始的数组大小，并计算数组扩容的阈值。 12345678910private void inflateTable(int toSize) &#123; &#x2F;&#x2F; 保证数组大小一定是 2 的 n 次方。 &#x2F;&#x2F; 比如这样初始化：new HashMap(20)，那么处理成初始数组大小是 32 int capacity &#x3D; roundUpToPowerOf2(toSize); &#x2F;&#x2F; 计算扩容阈值：capacity * loadFactor threshold &#x3D; (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); &#x2F;&#x2F; 算是初始化数组吧 table &#x3D; new Entry[capacity]; initHashSeedAsNeeded(capacity); &#x2F;&#x2F;ignore&#125; 这里有一个将数组大小保持为 2 的 n 次方的做法，Java7 和 Java8 的 HashMap 和 ConcurrentHashMap 都有相应的要求，只不过实现的代码稍微有些不同，后面再看到的时候就知道了。 计算具体数组位置（indexFor）这个简单，我们自己也能 YY 一个：使用 key 的 hash 值对数组长度进行取模就可以了。 1234static int indexFor(int hash, int length) &#123; &#x2F;&#x2F; assert Integer.bitCount(length) &#x3D;&#x3D; 1 : &quot;length must be a non-zero power of 2&quot;; return hash &amp; (length-1);&#125; 这个方法很简单，简单说就是取 hash 值的低 n 位。如在数组长度为 32 的时候，其实取的就是 key 的 hash 值的低 5 位，作为它在数组中的下标位置。 添加节点到链表中（addEntry）找到数组下标后，会先进行 key 判重，如果没有重复，就准备将新值放入到链表的表头。 12345678910111213141516171819void addEntry(int hash, K key, V value, int bucketIndex) &#123; &#x2F;&#x2F; 如果当前 HashMap 大小已经达到了阈值，并且新值要插入的数组位置已经有元素了，那么要扩容 if ((size &gt;&#x3D; threshold) &amp;&amp; (null !&#x3D; table[bucketIndex])) &#123; &#x2F;&#x2F; 扩容，后面会介绍一下 resize(2 * table.length); &#x2F;&#x2F; 扩容以后，重新计算 hash 值 hash &#x3D; (null !&#x3D; key) ? hash(key) : 0; &#x2F;&#x2F; 重新计算扩容后的新的下标 bucketIndex &#x3D; indexFor(hash, table.length); &#125; &#x2F;&#x2F; 往下看 createEntry(hash, key, value, bucketIndex);&#125;&#x2F;&#x2F; 这个很简单，其实就是将新值放到链表的表头，然后 size++void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e &#x3D; table[bucketIndex]; table[bucketIndex] &#x3D; new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 这个方法的主要逻辑就是先判断是否需要扩容，需要的话先扩容，然后再将这个新的数据插入到扩容后的数组的相应位置处的链表的表头。 数组扩容（resize）前面我们看到，在插入新值的时候，如果当前的 size 已经达到了阈值，并且要插入的数组位置上已经有元素，那么就会触发扩容，扩容后，数组大小为原来的 2 倍。 1234567891011121314void resize(int newCapacity) &#123; Entry[] oldTable &#x3D; table; int oldCapacity &#x3D; oldTable.length; if (oldCapacity &#x3D;&#x3D; MAXIMUM_CAPACITY) &#123; threshold &#x3D; Integer.MAX_VALUE; return; &#125; &#x2F;&#x2F; 新的数组 Entry[] newTable &#x3D; new Entry[newCapacity]; &#x2F;&#x2F; 将原来数组中的值迁移到新的更大的数组中 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table &#x3D; newTable; threshold &#x3D; (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 扩容就是用一个新的大数组替换原来的小数组，并将原来数组中的值迁移到新的数组中。 由于是双倍扩容，迁移过程中，会将原来 table[i] 中的链表的所有节点，分拆到新的数组的 newTable[i]和 newTable[i + oldLength] 位置上。如原来数组长度是 16，那么扩容后，原来 table[0] 处的链表中的所有元素会被分配到新数组中 newTable[0] 和 newTable[16] 这两个位置。代码比较简单，这里就不展开了。 get 过程分析相对于 put 过程，get 过程是非常简单的。 根据 key 计算 hash 值。找到相应的数组下标：hash &amp; (length - 1)。遍历该数组位置处的链表，直到找到相等(==或equals)的 key。 123456789101112131415161718192021222324252627public V get(Object key) &#123; &#x2F;&#x2F; 之前说过，key 为 null 的话，会被放到 table[0]，所以只要遍历下 table[0] 处的链表就可以了 if (key &#x3D;&#x3D; null) return getForNullKey(); &#x2F;&#x2F; Entry&lt;K,V&gt; entry &#x3D; getEntry(key); return null &#x3D;&#x3D; entry ? null : entry.getValue();&#125;getEntry(key):final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size &#x3D;&#x3D; 0) &#123; return null; &#125; int hash &#x3D; (key &#x3D;&#x3D; null) ? 0 : hash(key); &#x2F;&#x2F; 确定数组下标，然后从头开始遍历链表，直到找到为止 for (Entry&lt;K,V&gt; e &#x3D; table[indexFor(hash, table.length)]; e !&#x3D; null; e &#x3D; e.next) &#123; Object k; if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; Java8 中 HashMapJava8 对 HashMap 进行了一些修改，最大的不同就是利用了红黑树，所以其由 数组+链表+红黑树 组成。 根据 Java7 HashMap 的介绍，我们知道，查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。 为了降低这部分的开销，在 Java8 中，当链表中的元素达到了 8 个时，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。 来一张图简单示意一下吧： 注意，上图是示意图，主要是描述结构，不会达到这个状态的，因为这么多数据的时候早就扩容了。 下面，我们还是用代码来介绍吧，个人感觉，Java8 的源码可读性要差一些，不过精简一些。 Java7 中使用 Entry 来代表每个 HashMap 中的数据节点，Java8 中使用 Node，基本没有区别，都是 key，value，hash 和 next 这四个属性，不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。 我们根据数组元素中，第一个节点数据类型是 Node 还是 TreeNode 来判断该位置下是链表还是红黑树的。 put 过程分析123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; // 第三个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作// 第四个参数 evict 我们这里不关心 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; &#x2F;&#x2F; 第一次 put 值的时候，会触发下面的 resize()，类似 java7 的第一次 put 也要初始化数组长度 &#x2F;&#x2F; 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量 if ((tab &#x3D; table) &#x3D;&#x3D; null || (n &#x3D; tab.length) &#x3D;&#x3D; 0) n &#x3D; (tab &#x3D; resize()).length; &#x2F;&#x2F; 找到具体的数组下标，如果此位置没有值，那么直接初始化一下 Node 并放置在这个位置就可以了 if ((p &#x3D; tab[i &#x3D; (n - 1) &amp; hash]) &#x3D;&#x3D; null) tab[i] &#x3D; newNode(hash, key, value, null); else &#123;&#x2F;&#x2F; 数组该位置有数据 Node&lt;K,V&gt; e; K k; &#x2F;&#x2F; 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是&quot;相等&quot;，如果是，取出这个节点 if (p.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; p.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) e &#x3D; p; &#x2F;&#x2F; 如果该节点是代表红黑树的节点，调用红黑树的插值方法，本文不展开说红黑树 else if (p instanceof TreeNode) e &#x3D; ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; &#x2F;&#x2F; 到这里，说明数组该位置上是一个链表 for (int binCount &#x3D; 0; ; ++binCount) &#123; &#x2F;&#x2F; 插入到链表的最后面(Java7 是插入到链表的最前面) if ((e &#x3D; p.next) &#x3D;&#x3D; null) &#123; p.next &#x3D; newNode(hash, key, value, null); &#x2F;&#x2F; TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 8 个 &#x2F;&#x2F; 会触发下面的 treeifyBin，也就是将链表转换为红黑树 if (binCount &gt;&#x3D; TREEIFY_THRESHOLD - 1) &#x2F;&#x2F; -1 for 1st treeifyBin(tab, hash); break; &#125; &#x2F;&#x2F; 如果在该链表中找到了&quot;相等&quot;的 key(&#x3D;&#x3D; 或 equals) if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) &#x2F;&#x2F; 此时 break，那么 e 为链表中[与要插入的新值的 key &quot;相等&quot;]的 node break; p &#x3D; e; &#125; &#125; &#x2F;&#x2F; e!&#x3D;null 说明存在旧值的key与要插入的key&quot;相等&quot; &#x2F;&#x2F; 对于我们分析的put操作，下面这个 if 其实就是进行 &quot;值覆盖&quot;，然后返回旧值 if (e !&#x3D; null) &#123; V oldValue &#x3D; e.value; if (!onlyIfAbsent || oldValue &#x3D;&#x3D; null) e.value &#x3D; value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; &#x2F;&#x2F; 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 和 Java7 稍微有点不一样的地方就是，Java7 是先扩容后插入新值的，Java8 先插值再扩容，不过这个不重要。 数组扩容resize() 方法用于初始化数组或数组扩容，每次扩容后，容量为原来的 2 倍，并进行数据迁移。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab &#x3D; table; int oldCap &#x3D; (oldTab &#x3D;&#x3D; null) ? 0 : oldTab.length; int oldThr &#x3D; threshold; int newCap, newThr &#x3D; 0; if (oldCap &gt; 0) &#123; &#x2F;&#x2F; 对应数组扩容 if (oldCap &gt;&#x3D; MAXIMUM_CAPACITY) &#123; threshold &#x3D; Integer.MAX_VALUE; return oldTab; &#125; &#x2F;&#x2F; 将数组大小扩大一倍 else if ((newCap &#x3D; oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;&#x3D; DEFAULT_INITIAL_CAPACITY) &#x2F;&#x2F; 将阈值扩大一倍 newThr &#x3D; oldThr &lt;&lt; 1; &#x2F;&#x2F; double threshold &#125; else if (oldThr &gt; 0) &#x2F;&#x2F; 对应使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候 newCap &#x3D; oldThr; else &#123;&#x2F;&#x2F; 对应使用 new HashMap() 初始化后，第一次 put 的时候 newCap &#x3D; DEFAULT_INITIAL_CAPACITY; newThr &#x3D; (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr &#x3D;&#x3D; 0) &#123; float ft &#x3D; (float)newCap * loadFactor; newThr &#x3D; (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold &#x3D; newThr; &#x2F;&#x2F; 用新的数组大小初始化新的数组 Node&lt;K,V&gt;[] newTab &#x3D; (Node&lt;K,V&gt;[])new Node[newCap]; table &#x3D; newTab; &#x2F;&#x2F; 如果是初始化数组，到这里就结束了，返回 newTab 即可 if (oldTab !&#x3D; null) &#123; &#x2F;&#x2F; 开始遍历原数组，进行数据迁移。 for (int j &#x3D; 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e &#x3D; oldTab[j]) !&#x3D; null) &#123; oldTab[j] &#x3D; null; &#x2F;&#x2F; 如果该数组位置上只有单个元素，那就简单了，简单迁移这个元素就可以了 if (e.next &#x3D;&#x3D; null) newTab[e.hash &amp; (newCap - 1)] &#x3D; e; &#x2F;&#x2F; 如果是红黑树，具体我们就不展开了 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; &#x2F;&#x2F; 这块是处理链表的情况， &#x2F;&#x2F; 需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序 &#x2F;&#x2F; loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表，代码还是比较简单的 Node&lt;K,V&gt; loHead &#x3D; null, loTail &#x3D; null; Node&lt;K,V&gt; hiHead &#x3D; null, hiTail &#x3D; null; Node&lt;K,V&gt; next; do &#123; next &#x3D; e.next; if ((e.hash &amp; oldCap) &#x3D;&#x3D; 0) &#123; if (loTail &#x3D;&#x3D; null) loHead &#x3D; e; else loTail.next &#x3D; e; loTail &#x3D; e; &#125; else &#123; if (hiTail &#x3D;&#x3D; null) hiHead &#x3D; e; else hiTail.next &#x3D; e; hiTail &#x3D; e; &#125; &#125; while ((e &#x3D; next) !&#x3D; null); if (loTail !&#x3D; null) &#123; loTail.next &#x3D; null; &#x2F;&#x2F; 第一条链表 newTab[j] &#x3D; loHead; &#125; if (hiTail !&#x3D; null) &#123; hiTail.next &#x3D; null; &#x2F;&#x2F; 第二条链表的新的位置是 j + oldCap，这个很好理解 newTab[j + oldCap] &#x3D; hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; get 过程分析相对于 put 来说，get 真的太简单了。 计算 key 的 hash 值，根据 hash 值找到对应数组下标: hash &amp; (length-1).判断数组该位置处的元素是否刚好就是我们要找的，如果不是，走第三步.判断该元素类型是否是 TreeNode，如果是，用红黑树的方法取数据，如果不是，走第四步.遍历链表，直到找到相等(==或equals)的 key. public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断第一个节点是不是就是需要的 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; // 判断是否是红黑树 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 链表遍历 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125;","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"源码","slug":"源码","permalink":"https://dengchuncui.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"hashmap","slug":"hashmap","permalink":"https://dengchuncui.github.io/tags/hashmap/"}]},{"title":"设计模式 行为型模式 观察者模式","slug":"【行为型模式】 观察者模式","date":"2020-09-14T12:01:24.000Z","updated":"2021-05-04T06:24:16.447Z","comments":true,"path":"2020/09/14/【行为型模式】 观察者模式/","link":"","permalink":"https://dengchuncui.github.io/2020/09/14/%E3%80%90%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E3%80%91%20%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/","excerpt":"描述观察者模式又叫发布订阅模式,拥有一个监听者,如果一个被监听者发生了改变则会通知到所有监听者。例子,警察和嫌疑犯之间就是观察者模式。微信朋友圈,相对于好友,你就是观察者,微信好友发送朋友圈你会收到通知","text":"描述观察者模式又叫发布订阅模式,拥有一个监听者,如果一个被监听者发生了改变则会通知到所有监听者。例子,警察和嫌疑犯之间就是观察者模式。微信朋友圈,相对于好友,你就是观察者,微信好友发送朋友圈你会收到通知 类图 代码实现123456789101112public class PoliceMan &#123; private String name; public PoliceMan(String name) &#123; this.name &#x3D; name; &#125; public void name() &#123; System.out.println(&quot;我是:&quot; + name + &quot;收到消息&quot;); &#125;&#125; 123456789101112131415161718192021222324public class XianFan1 &#123; private String name; public XianFan1(String name) &#123; this.name &#x3D; name; &#125; private List&lt;PoliceMan&gt; policeManList &#x3D; new ArrayList&lt;&gt;(); public void addPolice(PoliceMan policeMan) &#123; if (!policeManList.contains(policeMan)) &#123; policeManList.add(policeMan); &#125; &#125; public void run() &#123; System.out.println(name + &quot;跑了&quot;); notifyAllPoliceMan(); &#125; public void notifyAllPoliceMan()&#123; policeManList.stream().forEach(i -&gt; i.name()); &#125;&#125; 测试类 12345678910111213public class Main &#123; public static void main(String[] args) &#123; PoliceMan policeManA &#x3D;new PoliceMan(&quot;警察:A&quot;); PoliceMan policeManB &#x3D;new PoliceMan(&quot;警察:B&quot;); PoliceMan policeManC &#x3D;new PoliceMan(&quot;警察:C&quot;); XianFan1 xianFan1 &#x3D;new XianFan1(&quot;嫌犯1&quot;); xianFan1.addPolice(policeManA); xianFan1.addPolice(policeManB); xianFan1.addPolice(policeManC); xianFan1.run(); &#125;&#125; 总结可以看到在被观察者类上面存放观察者的集合,在调用观察者的相关方法的时候循环调用观察者,从而实现发布订阅模式。被观察者需要提供添加观察者和通知观察者方法 观察者和被观察者的实现复合开闭原则 实现通知模式 如果观察者过多通知的时间成本加大 观察者只知道目标变化,但是具体变化情况不得而知。可以定义相关事件来区分","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式 结构型模式 桥接模式","slug":"【结构型模式】 桥接模式","date":"2020-08-29T13:11:21.000Z","updated":"2021-05-04T06:21:49.528Z","comments":true,"path":"2020/08/29/【结构型模式】 桥接模式/","link":"","permalink":"https://dengchuncui.github.io/2020/08/29/%E3%80%90%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F%E3%80%91%20%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/","excerpt":"描述 桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。","text":"描述 桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。 这种模式涉及到一个作为桥接的接口，使得实体类的功能独立于接口实现类。这两种类型的类可被结构化改变而互不影响。例子：总共又长方形、正方形、三角形、圆形四个形状。如果现在有需求每个形状要有红、黄、蓝，三个颜色。最能想到的是在每个形状下在创建长方形-红、长方形-黄、长方形-蓝、正方形-红、正方形-黄、正方形-蓝…..等等来进行实现。而使用桥接模式则创建一个抽象的 颜色类。并且实现红色类,黄色类,蓝色类。扩充的形状类存储颜色的引用对象在创建形状的时候去添加对应的颜色引用对象。 类图 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public interface Colour &#123; void desc();&#125;public class Blue implements Colour &#123; @Override public void desc() &#123; System.out.println(&quot;蓝色&quot;); &#125;&#125;public class Red implements Colour &#123; @Override public void desc() &#123; System.out.println(&quot;红色&quot;); &#125;&#125;public class Yellow implements Colour&#123; @Override public void desc() &#123; System.out.println(&quot;黄色&quot;); &#125;&#125;public abstract class Graphical &#123; private Colour colour; public Graphical(Colour colour) &#123; this.colour &#x3D; colour; &#125; abstract void desc(); public Colour getColour()&#123; return colour; &#125;&#125;public class Rectangle extends Graphical &#123; public Rectangle(Colour colour)&#123; super(colour); &#125; @Override public void desc() &#123; System.out.println(&quot;长方形&quot;); getColour().desc(); &#125;&#125;public class Square extends Graphical &#123; public Square(Colour colour)&#123; super(colour); &#125; @Override public void desc() &#123; System.out.println(&quot;正方形&quot;); getColour().desc(); &#125;&#125;public class Triangle extends Graphical &#123; public Triangle(Colour colour) &#123; super(colour); &#125; @Override public void desc() &#123; System.out.println(&quot;三角形&quot;); getColour().desc(); &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Rectangle rectangle &#x3D; new Rectangle(new Blue()); rectangle.desc(); &#125;&#125; 优点 解耦解耦解耦解耦解耦解耦解耦 实现细节对客户透明，可以对用户隐藏实现细节缺点桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式 结构型模式 外观模式","slug":"【结构型模式】 外观模式","date":"2020-08-19T13:12:31.000Z","updated":"2021-05-04T06:22:25.378Z","comments":true,"path":"2020/08/19/【结构型模式】 外观模式/","link":"","permalink":"https://dengchuncui.github.io/2020/08/19/%E3%80%90%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F%E3%80%91%20%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/","excerpt":"描述外观模式属于结构型模式的一种,当子系统的方法众多,可以引用外观模式在外观类将子方法的方法封装起来,外观类提供简单的api方法。外观类的方法屏蔽掉了复杂的api调用","text":"描述外观模式属于结构型模式的一种,当子系统的方法众多,可以引用外观模式在外观类将子方法的方法封装起来,外观类提供简单的api方法。外观类的方法屏蔽掉了复杂的api调用 类图下图为外观模式类图 代码12345public class SubMethod1 &#123; public void method1()&#123; System.out.println(&quot;子系统中类1的方法1&quot;); &#125;&#125; 12345public class SubMethod2 &#123; public void method2()&#123; System.out.println(&quot;子系统中类2方法2&quot;); &#125; &#125; 12345public class SubMethod3 &#123; public void method3()&#123; System.out.println(&quot;子系统类3方法3&quot;); &#125;&#125; 1234567891011121314public class Facader &#123; private SubMethod1 sm1 &#x3D; new SubMethod1(); private SubMethod2 sm2 &#x3D; new SubMethod2(); private SubMethod3 sm3 &#x3D; new SubMethod3(); public void facMethod1()&#123; sm1.method1(); sm2.method2(); &#125; public void facMethod2()&#123; sm2.method2(); sm3.method3(); sm1.method1(); &#125;&#125; 123456789public class Clienter &#123; public static void main(String[] args) &#123; Facader face &#x3D; new Facader(); face.facMethod1();&#x2F;&#x2F; face.facMethod2(); &#125;&#125; 优点外观模式的优点对客户屏蔽子系统组件，减少了客户处理的对象数目并使得子系统使用起来更加容易。通过引入外观模式，客户代码将变得很简单，与之关联的对象也很少。实现了子系统与客户之间的松耦合关系，这使得子系统的组件变化不会影响到调用它的客户类，只需要调整外观类即可。降低了大型软件系统中的编译依赖性，并简化了系统在不同平台之间的移植过程，因为编译一个子系统一般不需要编译所有其他的子系统。一个子系统的修改对其他子系统没有任何影响，而且子系统内部变化也不会影响到外观对象。只是提供了一个访问子系统的统一入口，并不影响用户直接使用子系统类。 缺点外观模式的缺点不能很好地限制客户使用子系统类，如果对客户访问子系统类做太多的限制则减少了可变性和灵活性。在不引入抽象外观类的情况下，增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。 自己总结优点： 功能调用子系统的方法太多,不好维护使用外观模式来屏蔽复杂子系统方法的调用,代码更简单 子类和使用者之间体现了松耦合的关系,修改功能只需要修改外观类即可缺点:如果使用太多子系统的方法,会使外观类不好维护,可变性灵活性下降","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式 结构型模式 适配器模式","slug":"【结构型模式】 适配器模式","date":"2020-08-15T10:12:31.000Z","updated":"2021-05-04T06:22:09.199Z","comments":true,"path":"2020/08/15/【结构型模式】 适配器模式/","link":"","permalink":"https://dengchuncui.github.io/2020/08/15/%E3%80%90%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F%E3%80%91%20%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/","excerpt":"描述 适配器模式属于结构性模式,将适配类的api转化为目标类的api,如mac电脑使用的是typec的接口,连接显示器需要hdmi接口。我们要使用mac连接显示器,需要使用扩展坞,这其实就是适配器模式。 类图","text":"描述 适配器模式属于结构性模式,将适配类的api转化为目标类的api,如mac电脑使用的是typec的接口,连接显示器需要hdmi接口。我们要使用mac连接显示器,需要使用扩展坞,这其实就是适配器模式。 类图 分类 类适配是基于继承实现的 对象适配使用组合方式实现,更加灵活代码123456public class MacInterface &#123; public void typeC()&#123; System.out.println(&quot;type 已经连接..&quot;); &#125;&#125; 12345public interface Monitor &#123; void hdml();&#125; 类适配1234567public class ExtendUtil extends MacInterface implements Monitor &#123; @Override public void hdml() &#123; super.typeC(); &#125;&#125; 对象适配12345678910public class ExtendUtilV2 implements Monitor&#123; private MacInterface macInterface; public ExtendUtilV2()&#123; macInterface &#x3D;new MacInterface(); &#125; @Override public void hdml() &#123; macInterface.typeC(); &#125;&#125; 测试代码12345678910public class Main &#123; public static void main(String[] args) &#123; &#x2F;&#x2F; 类适配模式 ExtendUtil extendUtil &#x3D;new ExtendUtil(); extendUtil.hdml(); &#x2F;&#x2F; 对象适配模式 ExtendUtilV2 extendUtilV2 &#x3D;new ExtendUtilV2(); extendUtilV2.hdml(); &#125;&#125; 总结 优点 复用性好,可以适配系统中已经存在的方法,无需重写 扩展性好,可以在适配类中添加想要适配的方法 缺点 系统中一旦适配类变多则导致系统代码混乱。代码晦涩难懂","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式 创建型模式 单例模式","slug":"【创建型模式】单例模式","date":"2020-08-02T10:16:31.000Z","updated":"2021-05-04T06:21:08.509Z","comments":true,"path":"2020/08/02/【创建型模式】单例模式/","link":"","permalink":"https://dengchuncui.github.io/2020/08/02/%E3%80%90%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E3%80%91%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","excerpt":"描述 单例模式对于开发人员来讲并不陌生通过单利模式可以控制应用程序中,只有一个对象的实例,分为饿汉式和懒汉式.饿汉式在类加载的时候就初始化,懒汉模式拥有延迟加载的思想,在使用的时候创建。实现单例模式的思想就是私有构造方法。通过getInstance()方法获取对应实例","text":"描述 单例模式对于开发人员来讲并不陌生通过单利模式可以控制应用程序中,只有一个对象的实例,分为饿汉式和懒汉式.饿汉式在类加载的时候就初始化,懒汉模式拥有延迟加载的思想,在使用的时候创建。实现单例模式的思想就是私有构造方法。通过getInstance()方法获取对应实例 饿汉式12345678public class Singleton&#123; private static final Singleton singleton &#x3D;new Singleton();private Singleton&#123; &#125; public static Singleton getInstance()&#123; return singleton;&#125;&#125; 懒汉式12345678910111213public class Singleton&#123; private static final singleton &#x3D; null;private Singleton&#123; &#125; private Singleton&#123; &#125;public static Singleton getInstance()&#123;if(null&#x3D;&#x3D;singleton)&#123; singleton &#x3D;new Singleton();&#125;return singleton;&#125;&#125; 上面的实现方式在多线程的环境下是线程不安全的,下面来个线程安全的 123456789101112131415161718public class Singleton&#123;&#x2F;&#x2F; volatile 保证每次都从主内存中取,不会在工作线程内存中取,效率不高 private static volatile final singleton &#x3D; null; private Singleton&#123; &#125;public static Singleton getInstance()&#123;if(null&#x3D;&#x3D;singleton)&#123; &#x2F;&#x2F;双重锁检查 synchronized(Singleton.class) &#123; if(null&#x3D;&#x3D;singleton)&#123; singleton &#x3D;new Singleton(); &#125; &#125;&#125;return singleton;&#125;&#125; 下面是利用jvm加载静态内部类的方式实现单例模式.jvm初始化类 123456789public class Singleton&#123; private static class SingletonHodle&#123; private static Singleton singleton &#x3D;new Singleton();public static getInstance()&#123;&#x2F;&#x2F; 保证jvm加载SingletonHodle初始Singleton实例return SingletonHodle.singleton; &#125; &#125;&#125; 使用枚举实现单子例模式 1234567public enum Singleton &#123; uniqueInstance;&#x2F;&#x2F; 定义一个枚举的元素，它就代表了Singleton的一个实例,因为枚举在编译成class文件,对应的属性就是 static final的保证了jvm初始化类的时候只能生成一个实例 public void singletonOperation() &#123; &#x2F;&#x2F; 功能处理 System.err.println(&quot;功能处理&quot;); &#125;&#125; 破快单利模式的三种方式 序列化 反射 clone如何避免单利模式被破快 序列化增加readResolve()方法,返回实例对象 反射创建标志位,is_create标志,如果is_create=true 则抛异常 clone重写clone方法,返回对应的instance jdk的实现我们 JDK 中，java.lang.Runtime 就是经典的单例模式(饿汉式)","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式 创建型模式 创建者模式","slug":"【创建型模式】 创建者模式","date":"2020-07-25T06:16:31.000Z","updated":"2021-05-04T06:20:35.037Z","comments":true,"path":"2020/07/25/【创建型模式】 创建者模式/","link":"","permalink":"https://dengchuncui.github.io/2020/07/25/%E3%80%90%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E3%80%91%20%E5%88%9B%E5%BB%BA%E8%80%85%E6%A8%A1%E5%BC%8F/","excerpt":"概述1、定义：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示2、主要作用：在用户不知道对象的建造过程和细节的情况下就可以直接创建复杂的对象。3、如何使用：用户只需要给出指定复杂对象的类型和内容，建造者模式负责按顺序创建复杂对象（把内部的建造过程和细节隐藏起来）4、解决的问题：（1）、方便用户创建复杂的对象（不需要知道实现过程）（2）、代码复用性 &amp; 封装性（将对象构建过程和细节进行封装 &amp; 复用）5、注意事项：与工厂模式的区别是：建造者模式更加关注与零件装配的顺序，一般用来创建更为复杂的对象","text":"概述1、定义：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示2、主要作用：在用户不知道对象的建造过程和细节的情况下就可以直接创建复杂的对象。3、如何使用：用户只需要给出指定复杂对象的类型和内容，建造者模式负责按顺序创建复杂对象（把内部的建造过程和细节隐藏起来）4、解决的问题：（1）、方便用户创建复杂的对象（不需要知道实现过程）（2）、代码复用性 &amp; 封装性（将对象构建过程和细节进行封装 &amp; 复用）5、注意事项：与工厂模式的区别是：建造者模式更加关注与零件装配的顺序，一般用来创建更为复杂的对象 实现方式代码实现 抽象建造者（builder）：描述具体建造者的公共接口，一般用来定义建造细节的方法，并不涉及具体的对象部件的创建。 具体建造者（ConcreteBuilder）：描述具体建造者，并实现抽象建造者公共接口。 指挥者（Director）：调用具体建造者来创建复杂对象（产品）的各个部分，并按照一定顺序（流程）来建造复杂对象。 产品（Product）：描述一个由一系列部件组成较为复杂的对象。 12345678910111213141516&#x2F;** * Builder.java * 建造者 *&#x2F;abstract class Builder &#123; &#x2F;&#x2F;地基 abstract void bulidA(); &#x2F;&#x2F;钢筋工程 abstract void bulidB(); &#x2F;&#x2F;铺电线 abstract void bulidC(); &#x2F;&#x2F;粉刷 abstract void bulidD(); &#x2F;&#x2F;完工-获取产品 abstract Product getProduct();&#125; 1234567891011121314151617181920212223242526272829303132333435363738&#x2F;** * Product.java * 产品（房子） *&#x2F;public class Product &#123; private String buildA; private String buildB; private String buildC; private String buildD; public String getBuildA() &#123; return buildA; &#125; public void setBuildA(String buildA) &#123; this.buildA &#x3D; buildA; &#125; public String getBuildB() &#123; return buildB; &#125; public void setBuildB(String buildB) &#123; this.buildB &#x3D; buildB; &#125; public String getBuildC() &#123; return buildC; &#125; public void setBuildC(String buildC) &#123; this.buildC &#x3D; buildC; &#125; public String getBuildD() &#123; return buildD; &#125; public void setBuildD(String buildD) &#123; this.buildD &#x3D; buildD; &#125; @Override public String toString() &#123; return buildA+&quot;\\n&quot;+buildB+&quot;\\n&quot;+buildC+&quot;\\n&quot;+buildD+&quot;\\n&quot;+&quot;房子验收完成&quot;; &#125;&#125; 123456789101112131415161718192021222324252627282930&#x2F;** * ConcreteBuilder.java * 具体建造者(工人) *&#x2F;public class ConcreteBuilder extends Builder&#123; private Product product; public ConcreteBuilder() &#123; product &#x3D; new Product(); &#125; @Override void bulidA() &#123; product.setBuildA(&quot;地基&quot;); &#125; @Override void bulidB() &#123; product.setBuildB(&quot;钢筋工程&quot;); &#125; @Override void bulidC() &#123; product.setBuildC(&quot;铺电线&quot;); &#125; @Override void bulidD() &#123; product.setBuildD(&quot;粉刷&quot;); &#125; @Override Product getProduct() &#123; return product; &#125;&#125; 12345678910111213141516&#x2F;** * Director.java * 指挥者 *&#x2F;public class Director &#123; &#x2F;&#x2F;指挥工人按顺序造房 public Product create(Builder builder) &#123; builder.bulidA(); builder.bulidB(); builder.bulidC(); builder.bulidD(); return builder.getProduct(); &#125;&#125; 1234567891011&#x2F;** * Test.java * 测试类 *&#x2F;public class Test &#123; public static void main(String[] args) &#123; Director director &#x3D; new Director(); Product create &#x3D; director.create(new ConcreteBuilder()); System.out.println(create.toString()); &#125;&#125; 总结 Builder 抽象类定义构建的方法 具体实现类实现Builder相关的方法-叫具体建造者 指挥者操作操作具体建造者按照顺序创建对象 产品类有大量属性优点 按照顺序创建对象 创建代码可读性好 隐藏对象大量属性,可以设置一些属性的默认值缺点 代码冗余 具体建造者内部代码复杂,代码可读性差具体实现 protobuf生成的实体类1234SimpleRequest.Builder builder &#x3D; SimpleRequest.newBuilder();builder.setId(12341);builder.setName(&quot;你好&quot;);SimpleRequest request &#x3D; builder.build();","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式 创建型模式 抽象方法模式","slug":"【创建型模式】抽象方法模式","date":"2020-07-20T13:11:37.000Z","updated":"2021-05-04T06:20:52.276Z","comments":true,"path":"2020/07/20/【创建型模式】抽象方法模式/","link":"","permalink":"https://dengchuncui.github.io/2020/07/20/%E3%80%90%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E3%80%91%E6%8A%BD%E8%B1%A1%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/","excerpt":"概述 抽象方法模式是工厂方法模式的一种扩展,最简单的抽象方法模式会退化成了工厂方法模式,抽象方法模式提出了产品族的一个概念。那么什么是产品族呢？还是以汽车为例,汽车是一个产品的抽象,汽车的型号就是汽车的产品族比如,suv,轿车,跑车。如果工厂模式创建的不是一个简单的产品,而是多个产品族的情况,那么就需要使用抽象方法模式","text":"概述 抽象方法模式是工厂方法模式的一种扩展,最简单的抽象方法模式会退化成了工厂方法模式,抽象方法模式提出了产品族的一个概念。那么什么是产品族呢？还是以汽车为例,汽车是一个产品的抽象,汽车的型号就是汽车的产品族比如,suv,轿车,跑车。如果工厂模式创建的不是一个简单的产品,而是多个产品族的情况,那么就需要使用抽象方法模式 类图抽象方法模式需要以下几个角色 抽象工厂类 产品工厂类 抽象产品类 产品类 代码实现12345public abstract class AbstractCarFactory &#123; abstract void buildSuv(); abstract void buildJiaoche(); abstract void buildYueYeChe(); &#125; public class BaoJunCarFactory extends AbstractCarFactory { private BaojunCar baojunCar=new BaojunCar(); @Override void buildSuv() { baojunCar.suv(); } @Override void buildJiaoche() { baojunCar.jiaoche(); } @Override void buildYueYeChe() { baojunCar.yueyeche(); }} 1234567891011121314151617181920public class BMWCarFactory extends AbstractCarFactory &#123; private BMWCar bmwCar &#x3D;new BMWCar(); @Override void buildSuv() &#123; bmwCar.suv(); &#125; @Override void buildJiaoche() &#123; bmwCar.jiaoche(); &#125; @Override void buildYueYeChe() &#123; bmwCar.yueyeche(); &#125;&#125; 12345678910111213141516171819public class BaojunCar implements Car &#123; @Override public void yueyeche() &#123; System.out.println(&quot;宝骏 越野车&quot;); &#125; @Override public void jiaoche() &#123; System.out.println(&quot;宝骏 轿车&quot;); &#125; @Override public void suv() &#123; System.out.println(&quot;宝骏 suv&quot;); &#125;&#125; 12345678910111213141516public class BMWCar implements Car &#123; @Override public void yueyeche() &#123; System.out.println(&quot;宝马 越野车&quot;); &#125; @Override public void jiaoche() &#123; System.out.println(&quot;宝马 轿车&quot;); &#125; @Override public void suv() &#123; System.out.println(&quot;宝马 suv&quot;); &#125;&#125; 12345public interface Car &#123; void yueyeche(); void jiaoche(); void suv();&#125; 1234567891011121314public class Main &#123; public static void main(String[] args) &#123; BaoJunCarFactory baoJunCarFactory &#x3D;new BaoJunCarFactory(); baoJunCarFactory.buildJiaoche(); baoJunCarFactory.buildSuv(); baoJunCarFactory.buildYueYeChe(); BMWCarFactory bmwCarFactory &#x3D;new BMWCarFactory(); bmwCarFactory.buildJiaoche(); bmwCarFactory.buildSuv(); bmwCarFactory.buildYueYeChe(); &#125;&#125; 可以看到我们的抽象工厂定义了多个抽象方法,这也就是为什么叫抽象方法模式的原因了。实际上和工厂方法模式一样。只是有产品族抽象方法的概念 优缺点优点： 复合高内聚低耦合的开发设计规范,抽象工厂模式将创建产品的逻辑收敛起来,如果更换产品只需要选择对应的工厂方法即可 增加具体产品工厂和产品很方便 当产品族中的多个对象一起工作的时候,客户端只能使用同一个产品族的对象缺点： 开闭原则的倾斜性,增加产品和产品工厂很方便,增加产品族很困难,所以设计抽象方法的时候一定要尽可能多的设计抽象方法 应用场景客户端切换界面主题, 各个控件对象的构造过程都收敛到同一个工厂类中","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式 创建型模式 简单工厂模式","slug":"【创建型模式】简单工厂模式","date":"2020-07-11T14:13:31.000Z","updated":"2021-05-04T06:21:35.500Z","comments":true,"path":"2020/07/11/【创建型模式】简单工厂模式/","link":"","permalink":"https://dengchuncui.github.io/2020/07/11/%E3%80%90%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E3%80%91%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","excerpt":"概述简单工厂模式又叫静态工厂模式,是属于创建型模式,工厂方法通过参数来控制创建不通的对象,这些对象都继承同一个夫类。 类图","text":"概述简单工厂模式又叫静态工厂模式,是属于创建型模式,工厂方法通过参数来控制创建不通的对象,这些对象都继承同一个夫类。 类图 代码实现12345678910111213public class CarFactory &#123; public static Car getCar(String name) &#123; if (&quot;BMW&quot;.equals(name)) &#123; return new BMWCar(); &#125; if (&quot;BAOJUN&quot;.equals(name)) &#123; return new BaojunCar(); &#125; throw new RuntimeException(&quot;unsupport car name &quot;); &#125;&#125; 1234public interface Car &#123; void desc();&#125; 123456public class BMWCar implements Car &#123; @Override public void desc() &#123; System.out.println(&quot;我是宝马～&quot;); &#125;&#125; 123456public class BaojunCar implements Car &#123; @Override public void desc() &#123; System.out.println(&quot;我是宝骏！&quot;); &#125;&#125; 产品类（宝马、宝骏）都继承Car类 工厂类根据入参不同返回不通的产品下面是主方法12345678910public class Main &#123; public static void main(String[] args) &#123; Car bmw &#x3D; CarFactory.getCar(&quot;BMW&quot;); bmw.desc(); Car baojun &#x3D; CarFactory.getCar(&quot;BAOJUN&quot;); baojun.desc(); Car xxx &#x3D; CarFactory.getCar(&quot;xxx&quot;); xxx.desc(); &#125;&#125; 结果： 优缺点优点： 通过入参控制返回不同的产品,隐藏生成产品的逻辑,调用方属于消费者 调用方只需要记录相关类的参数即可创建对应的类,避免了创建类名复杂,不好记忆的问题 相关参数可以放到配置文件中,一定成都上增加了灵活性缺点： 所有的类创建都在工厂类创建,一但工厂类发生问题所有的产品的创建都受到影响 扩展性差,如果增加新的产品需要在工厂类增加代码,导致工厂类过于复杂且庞大 产品的创建基于静态方法,造成产品无法形成基于继承的等级结构应用场景 加密场景 KeyGenerator keyGen=KeyGenerator.getInstance(“DESede”); DateFormat JDK类库中广泛使用了简单工厂模式，如工具类java.text.DateFormat，它用于格式化一个本地日期或者时间。 参考地址 图说设计模式 设计模式-简单工厂模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式 七大设计原则","slug":"设计模式 七大设计原则","date":"2020-06-29T13:12:34.000Z","updated":"2021-05-04T06:23:25.664Z","comments":true,"path":"2020/06/29/设计模式 七大设计原则/","link":"","permalink":"https://dengchuncui.github.io/2020/06/29/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%20%E4%B8%83%E5%A4%A7%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/","excerpt":"","text":"下面是我对7大设计原则自己的理解 单一原则一个类只做一件事情 里氏替换原则1.合理继承2.继承 子类是为了扩展父类,而不是重写相关方法。 依赖倒置原则高模块不应该直接依赖低模块,而是应该依赖其抽象 开闭原则对扩展开放,对修改关闭 迪莱米原则一个类引用类一个类,被引用类应该尽可能的封装自己的属性和方法,让别的类知道的越少越好 组合复合原则不推荐使用继承,可以使用组合的方式进行实现 接口隔离原则一个类对于另一个类的依赖,应该建立在最小的接口上,使用接口隔离","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"java 基础知识 动态代理 cglib代理","slug":"java 基础知识-动态代理-cglib代理","date":"2020-06-25T13:12:34.000Z","updated":"2021-05-04T06:27:28.325Z","comments":true,"path":"2020/06/25/java 基础知识-动态代理-cglib代理/","link":"","permalink":"https://dengchuncui.github.io/2020/06/25/java%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86-cglib%E4%BB%A3%E7%90%86/","excerpt":"一、cglib代理介绍cglib代理是实现动态代理的另一种方式,CGLIB是一个功能强大，高性能的代码生成包。它为没有实现接口的类提供代理，为JDK的动态代理提供了很好的补充。通常可以使用Java的动态代理创建代理，但当要代理的类没有实现接口或者为了更好的性能，CGLIB是一个好的选择 二、cglib的原理 动态生成目标类的代理类,重写代理类的所有非final修饰的方法,子类使用方法拦截的方式实现目标类的增强,所以cglib代理比jdk反射代理效率更高,并且能代理类,而jdk代理只能代理接口 底层使用asm字节码框架生成代理类,而不是使用反射生成类 缺点不能代理被final修饰的方法","text":"一、cglib代理介绍cglib代理是实现动态代理的另一种方式,CGLIB是一个功能强大，高性能的代码生成包。它为没有实现接口的类提供代理，为JDK的动态代理提供了很好的补充。通常可以使用Java的动态代理创建代理，但当要代理的类没有实现接口或者为了更好的性能，CGLIB是一个好的选择 二、cglib的原理 动态生成目标类的代理类,重写代理类的所有非final修饰的方法,子类使用方法拦截的方式实现目标类的增强,所以cglib代理比jdk反射代理效率更高,并且能代理类,而jdk代理只能代理接口 底层使用asm字节码框架生成代理类,而不是使用反射生成类 缺点不能代理被final修饰的方法 三、cglib代理的实现public static void main(String[] args) &#123; System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, &quot;resource&quot;); Dog dog =new Dog(); Enhancer enhancer =new Enhancer(); //设置目前类 enhancer.setSuperclass(Dog.class); //设置拦截器 enhancer.setCallback(new MethodInterceptor() &#123; public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(&quot;呵呵,我是增强&quot;); return methodProxy.invokeSuper(o,objects); &#125; &#125;); Dog dogProxy = (Dog) enhancer.create(); dogProxy.run(); &#125; 四、invokeSuper()方法因为cglib代理是继承目标类,并且重写方法,所以这里调用invokesuper方法,调用父类的方法 五、cglib原理上图可以看到cglib方式会在内存中生成,3个字节码文件.可以使用 System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, “resource”);方法将字节码文件写到相关目录。 可以看到代理类实现了目标代理类 可以看到重写run方法,先回去回调方法,如果获取不到就加载回调方法,执行intercept 方法 FastClass机制FastClass提出了index下标的概念,通过index保存方法的引用信息,将反射调用转化为方法的直接调用,体现所谓的fast 通过方法名计算hashcode值,通过hashcode找到方法对应的index 通过index 调用invoke方法,invoke方法通过index判断执行那个方法 总结 动态代理类通过实现invocationHandler接口 通过Proxy.newProxyInstance(factory.getClass().getClassLoader(),person.getClass().getInterfaces(),this)方法复制一份代理的类并且生成字节码文件到内存中,生成的代理类 继承了Proxy类 并且实现了代理接口调用生成的动态代理类中实现的方法,其中调用了其实现的方法，在方法中通过invocationHandler的invoke()方法jdk动态代理的缺点 不能代理类,需要实现invocationHandler接口jdk动态代理和cglib生成字节码的方式不通 cglib动态代理 可以动态代理类因为cglib动态生成的类是继承原类,所以可以动态代理到类 jdk动态代理实现了自己的顶层接口继承了proxy类","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"}]},{"title":"java 基础知识 动态代理 jdk代理","slug":"java 基础知识-动态代理-jdk代理","date":"2020-06-15T12:11:22.000Z","updated":"2021-05-04T06:28:27.250Z","comments":true,"path":"2020/06/15/java 基础知识-动态代理-jdk代理/","link":"","permalink":"https://dengchuncui.github.io/2020/06/15/java%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86-jdk%E4%BB%A3%E7%90%86/","excerpt":"一、jdk动态代理动态代理分为jdk动态代理和cglib动态代理,本章讲解jdk动态代理 二、jdk动态代理如何实现 实现InvorcationHander接口,在invoke()方法实现增强 通过Proxy.newProxyInstance()方法获取到代理类 调用代理引用调用目标方法实现曾江","text":"一、jdk动态代理动态代理分为jdk动态代理和cglib动态代理,本章讲解jdk动态代理 二、jdk动态代理如何实现 实现InvorcationHander接口,在invoke()方法实现增强 通过Proxy.newProxyInstance()方法获取到代理类 调用代理引用调用目标方法实现曾江 三、代码实现123456789101112public static void main(String[] args) &#123; final Car car &#x3D; new BmwCar(); Car carProxy &#x3D; (Car) Proxy.newProxyInstance(Car.class.getClassLoader(), car.getClass().getInterfaces(), new InvocationHandler() &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;增强前&quot;); Object invoke &#x3D; method.invoke(car, args); System.out.println(&quot;增强后&quot;); return invoke; &#125; &#125;); carProxy.run(); &#125; 结果:四、实现原理可以看到通过Proxy.newProxyInstance()生成了目标对象的代理类,以二进制的方式加载到了内存中.那么代理类长什么样子呢？ 代理类继承了Proxy类并且实现了我们的car接口 在实现的run方法中,调用了h.invoke()方法 那么h是什么呢？ h是 Proxy类中的属性,就是InvoketionHander接口的引用,所以jdk代理类必须实现InvoketionHander接口jdk 动态代理实现图","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"}]},{"title":"java 基础知识 静态代理","slug":" java 基础知识-静态代理","date":"2020-06-11T11:11:12.000Z","updated":"2021-05-04T06:11:41.275Z","comments":true,"path":"2020/06/11/ java 基础知识-静态代理/","link":"","permalink":"https://dengchuncui.github.io/2020/06/11/%20java%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"一、什么是代理模式 定义给目标对象提供一个代理对象,由代理对象操作目标对象的引用。 目的通过操作代理对象,操作目标对象,降低程序的复杂性,可以使用代理类实现目标对象的增强。不改变目标对象实现功能则增加。代理模式的结构图","text":"一、什么是代理模式 定义给目标对象提供一个代理对象,由代理对象操作目标对象的引用。 目的通过操作代理对象,操作目标对象,降低程序的复杂性,可以使用代理类实现目标对象的增强。不改变目标对象实现功能则增加。代理模式的结构图 1234graph LR;bwmcar--&gt;car bwmcar--&gt;bwmproxy bwmproxy--&gt;car 二、java实现12345&#x2F;&#x2F;定义一个接口public interface Car &#123; public void run() ;&#125; 123456&#x2F;&#x2F;定义宝马车实现类public class BmwCar implements Car &#123; public void run() &#123; System.out.println(&quot;我是一个宝马车&quot;); &#125;&#125; 123456789101112131415&#x2F;&#x2F;定义宝马车实现类public class BmwCarProxy implements Car &#123; &#x2F;&#x2F;代理类拥有目标对象的引用 private BmwCar bmwCar; public void proxy(BmwCar bmwCar) &#123; this.bmwCar &#x3D; bmwCar; &#125; public void run() &#123; System.out.println(&quot;增强前&quot;); bmwCar.run(); System.out.println(&quot;增强后&quot;); &#125;&#125; 1234567public static void main(String[] args) &#123; BmwCar bmwCar &#x3D;new BmwCar(); BmwCarProxy proxy &#x3D;new BmwCarProxy(); proxy.proxy(bmwCar); &#x2F;&#x2F;调用代理类的方法 proxy.run(); &#125; 三、总结 静态代理模式可以在不改变目标对象的前提下,对目标对象实现方法的增加 每次增加增强方法都需要修改代码,违反开闭原则,扩展能力可维护性查","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"静态代理","slug":"静态代理","permalink":"https://dengchuncui.github.io/tags/%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"java NIO 相关(七) nio selector channel 的多路复用器","slug":"java NIO相关(七) nio selector(channel 的多路复用器)","date":"2020-05-30T10:21:13.000Z","updated":"2021-05-04T06:30:27.090Z","comments":true,"path":"2020/05/30/java NIO相关(七) nio selector(channel 的多路复用器)/","link":"","permalink":"https://dengchuncui.github.io/2020/05/30/java%20NIO%E7%9B%B8%E5%85%B3(%E4%B8%83)%20nio%20selector(channel%20%E7%9A%84%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%99%A8)/","excerpt":"一、概念选择器（selector）是selectableChannel对象的多路复用器,一个selector可以监控多个selectableChannel的io情况,selector可以实现一个线程单独管理多个channel,selector是非阻塞的核心","text":"一、概念选择器（selector）是selectableChannel对象的多路复用器,一个selector可以监控多个selectableChannel的io情况,selector可以实现一个线程单独管理多个channel,selector是非阻塞的核心 二、selector可以监控的事件类型 connect 客户端连接服务端事件 accept 服务端接受服务端事件 read 读事件 write 写事件 每次请求都是从客户端连接服务端(connect),服务端开始准备(accept),准备完成后开始读数据,处理完成之后再写数据 三、selector的常用方法 四、nio 的例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&#x2F;&#x2F;服务端public class NioServer &#123; private ServerSocketChannel serverSocketChannel; private Selector selector; private Integer port &#x3D; 8080; NioServer() &#123; try &#123; serverSocketChannel &#x3D; ServerSocketChannel.open().bind(new InetSocketAddress(port)); &#x2F;&#x2F;设置非阻塞 serverSocketChannel.configureBlocking(false); &#x2F;&#x2F;创建Selector selector &#x3D; Selector.open(); &#x2F;&#x2F;注册tcp 连接事件到 channel serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(&quot;服务端初始化完成,端口号:&quot; + port); &#125; catch (Exception ex) &#123; throw new RuntimeException(&quot;初始化服务端失败,ex:&quot;+ex); &#125; &#125; private void start() &#123; try &#123; &#x2F;&#x2F;获取查看selector 管理多少个channel while (selector.select() &gt; 0) &#123; &#x2F;&#x2F;走到这里肯定是selector发现channel有变化了,这个大哥把他管理的sekectedKeys拿出来遍历 Set&lt;SelectionKey&gt; selectionKeys &#x3D; selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator &#x3D; selectionKeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey selectionKey &#x3D; iterator.next(); &#x2F;&#x2F;selector 也不知道是什么变化所以就 各种判断一下,是 创建连接、还是准备就绪、还是读取数据、还是写数据、还是关闭连接 if (selectionKey.isConnectable()) &#123; System.out.println(&quot;用户建立连接&quot;); &#125; if (selectionKey.isAcceptable()) &#123; System.out.println(&quot;用户准备就绪&quot;); ServerSocketChannel serverSocketChannel &#x3D; (ServerSocketChannel) selectionKey.channel(); &#x2F;&#x2F;这样就拿到了发生变化的 socketChannel SocketChannel accept &#x3D; serverSocketChannel.accept(); accept.configureBlocking(false); &#x2F;&#x2F;把客户端的channel 注册到 selector 当客户端的socketChannel发生变化出发读逻辑 accept.register(selector, SelectionKey.OP_READ); &#125; if (selectionKey.isReadable()) &#123; System.out.println(&quot;读数据&quot;); SocketChannel socketChannel &#x3D; (SocketChannel) selectionKey.channel(); &#x2F;&#x2F;读数据得是由buffer ByteBuffer byteBuffer &#x3D; ByteBuffer.allocate(1024); &#x2F;&#x2F;切换到读模式 StringBuffer sb &#x3D; new StringBuffer(); while (socketChannel.read(byteBuffer) !&#x3D; -1) &#123; byteBuffer.flip(); sb.append(StandardCharsets.UTF_8.decode(byteBuffer)); byteBuffer.clear(); &#125; System.out.println(&quot;来自客户端的问候:&quot; + sb.toString()); &#x2F;&#x2F;来个写数据吧 socketChannel.register(selector,SelectionKey.OP_WRITE); &#125; if (selectionKey.isWritable()) &#123; System.out.println(&quot;写数据&quot;); System.out.println(&quot;不会写数据&quot;); selectionKey.channel().close(); &#125; if (selectionKey.isValid()) &#123; System.out.println(&quot;关闭数据&quot;); &#125; &#x2F;&#x2F;把当前的selection移除,因为后面事件还会加入 iterator.remove(); &#125; &#125; &#125; catch (Exception ex) &#123; throw new RuntimeException(&quot;服务异,ex:&quot;, ex); &#125; &#125; public static void main(String[] args) &#123; &#x2F;&#x2F;先定义服务端 NioServer nioServer &#x3D; new NioServer(); &#x2F;&#x2F;开启服务 nioServer.start(); &#125; 123456789101112131415161718&#x2F;&#x2F;客户端public class NioClint &#123; public static void main(String[] args) throws IOException &#123; SocketChannel open &#x3D; SocketChannel.open(); open.connect(new InetSocketAddress(&quot;127.0.0.1&quot;,8080)); open.configureBlocking(false); ByteBuffer byteBuffer &#x3D;ByteBuffer.allocate(1024); byteBuffer.flip(); String msg &#x3D;&quot;呵呵,你大爷&quot;; byteBuffer &#x3D; ByteBuffer.wrap(msg.getBytes(&quot;utf-8&quot;)); open.write(byteBuffer); byteBuffer.clear(); Socket socket &#x3D; open.socket(); SocketChannel channel &#x3D; socket.getChannel(); &#125;&#125;","categories":[{"name":"NIO 系列","slug":"NIO-系列","permalink":"https://dengchuncui.github.io/categories/NIO-%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"}]},{"title":"java 基础知识 字符集","slug":" java 基础知识点-字符集md","date":"2020-05-25T07:05:48.000Z","updated":"2021-05-04T06:13:19.973Z","comments":true,"path":"2020/05/25/ java 基础知识点-字符集md/","link":"","permalink":"https://dengchuncui.github.io/2020/05/25/%20java%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9-%E5%AD%97%E7%AC%A6%E9%9B%86md/","excerpt":"字符集相关概念编码： 字符串-&gt;字节数组 解码：字节数组-&gt;字符串 相关字符集介绍 ASCII (american standard code for information interchange 美国信息交换标准代码)7 bit 表示来表示一个字符，共计可以表示128中字符","text":"字符集相关概念编码： 字符串-&gt;字节数组 解码：字节数组-&gt;字符串 相关字符集介绍 ASCII (american standard code for information interchange 美国信息交换标准代码)7 bit 表示来表示一个字符，共计可以表示128中字符 Ios-8859-1 8 bit 表示一个字符 ，即使用一个字节 8 bit表示一个字符 共计可以表示 256个字符 Gb2312 2个字节表示一个汉字 Gbk 对 Gb2312的扩展 支持生僻字 Gb18030 表示汉字最多的 Big5 繁体中文 Unicode 最广泛的编码，两个字节表示一个字符 包含全球所有文字 缺点 ： 存储空间会变大(英文国家) Utf unicode是一个编码方式，而utf是一个存储方式 utf-8 是unicode的实现方式之一 Utf-16LE(小端) UTF16BE(大端) 文件起始位置 0xFEFF (BE) 0XFFFE(LE) Utf-8 变长字节表示形式 一般来说，utf-8 会通过3个字节表示一个中文","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"字符集","slug":"字符集","permalink":"https://dengchuncui.github.io/tags/%E5%AD%97%E7%AC%A6%E9%9B%86/"},{"name":"utf-8","slug":"utf-8","permalink":"https://dengchuncui.github.io/tags/utf-8/"}]},{"title":"java NIO 相关(六) pipe 和 FileChannel文件锁","slug":"java NIO相关(六) pipe 和 FileChannel文件锁","date":"2020-05-21T03:21:10.000Z","updated":"2021-05-04T06:30:10.927Z","comments":true,"path":"2020/05/21/java NIO相关(六) pipe 和 FileChannel文件锁/","link":"","permalink":"https://dengchuncui.github.io/2020/05/21/java%20NIO%E7%9B%B8%E5%85%B3(%E5%85%AD)%20pipe%20%E5%92%8C%20FileChannel%E6%96%87%E4%BB%B6%E9%94%81/","excerpt":"一、pipe概念 pipe 是nio管道2个线程之前的单项数据连接。 pipe 有2个通道一个是source通道一个是sink通道数据会写入到source通道从sink通道获取数据。如图：","text":"一、pipe概念 pipe 是nio管道2个线程之前的单项数据连接。 pipe 有2个通道一个是source通道一个是sink通道数据会写入到source通道从sink通道获取数据。如图： 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344public class PipeTest &#123;public static void main(String[] args) &#123; Pipe pipe &#x3D; null; ExecutorService exec &#x3D; Executors.newFixedThreadPool(2); try &#123; pipe &#x3D; Pipe.open(); final Pipe pipeTemp &#x3D; pipe; exec.submit(new Callable&lt;Object&gt;() &#123; @Override public Object call() throws Exception &#123; Pipe.SinkChannel sinkChannel &#x3D; pipeTemp.sink();&#x2F;&#x2F;向通道中写 while (true) &#123; TimeUnit.SECONDS.sleep(1); String newData &#x3D; &quot;Pipe Test At Time &quot; + System.currentTimeMillis(); ByteBuffer buf &#x3D; ByteBuffer.allocate(1024); buf.clear(); buf.put(newData.getBytes()); buf.flip(); while (buf.hasRemaining()) &#123; System.out.println(buf); sinkChannel.write(buf); &#125; &#125;&#125; &#125;); exec.submit(new Callable&lt;Object&gt;() &#123; @Override public Object call() throws Exception &#123;Pipe.SourceChannel sourceChannel &#x3D; pipeTemp.source();&#x2F;&#x2F;向 while (true) &#123; TimeUnit.SECONDS.sleep(1); ByteBuffer buf &#x3D; ByteBuffer.allocate(1024); buf.clear(); int bytesRead &#x3D; sourceChannel.read(buf); System.out.println(&quot;bytesRead&#x3D;&quot; + bytesRead); while (bytesRead &gt; 0) &#123; buf.flip(); byte b[] &#x3D; new byte[bytesRead]; int i &#x3D; 0; while (buf.hasRemaining()) &#123; b[i] &#x3D; buf.get(); System.out.printf(&quot;%X&quot;, b[i]); i++; &#125; String s &#x3D; new String(b); System.out.println(&quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;||&quot; + s); bytesRead &#x3D; sourceChannel.read(buf);&#125; 二、FileChannel文件锁 在通道中我们可以对文件或者部分文件进行上锁。上锁和我们了解的线程锁差不多，都是为 了保证数据的一致性。在文件通道 FileChannel 中可以对文件进行上锁，通过 FileLock 可以 对文件进行锁的释放。 文件加锁是建立在文件通道(FileChannel)之上的，套接字通道(SockeChannel)不考虑文 件加锁，因为它是不共享的。它对文件加锁有两种方式: lock tryLock 两种加锁方式默认都是对整个文件加锁，如果自己配置的话就可以控制加锁的文件范围: position 是加锁的开始位置，size 是加锁长度，shared 是用于控制该锁是共享的还是独占的。 lock 是阻塞式的，当有进程对锁进行读取时会等待锁的释放，在此期间它会一直等待; tryLock 是非阻塞式的，它尝试获得锁，如果这个锁不能获得，那么它会立即返回。 release 可以释放锁。在一个进程中在锁没有释放之前是无法再次获得锁的在 java 的 NIO 中，通道包下面有一个 FileLock 类，它主要是对文件锁工具的一个描述。在 上一小节中对文件的锁获取其实是 FileChannel 获取的(lock 与 trylock 是 FileChannel 的方 法)，它们返回一个 FileLock 对象。 这个类的核心方法有如下这些:boolean isShared() :判断锁是否为共享类型abstract boolean isValid() :判断锁是否有效boolean overlaps():判断此锁定是否与给定的锁定区域重叠 long position():返回文件内锁定区域中第一个字节的位置。abstract void release() :释放锁long size() :返回锁定区域的大小，以字节为单位 在文件锁中有 3 种方式可以释放文件锁: 锁类释放锁，调用 FileLock 的 release 方法 通道类关闭通道，调用 FileChannel 的 close 方法 jvm 虚拟机会在特定情况释放锁。 锁类型(独占式和共享式)我们先区分一下在文件锁中两种锁的区别: 独占式的锁就想我们上面测试的那样，只要有一个进程获取了独占锁，那么别的进程只能等待。 共享锁在一个进程获取的情况下，别的 进程还是可以读取被锁定的文件，但是别的进程不能写只能读。","categories":[{"name":"NIO 系列","slug":"NIO-系列","permalink":"https://dengchuncui.github.io/categories/NIO-%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"}]},{"title":"java NIO 相关(五) 分散(Scatter) 和聚集(Gather)","slug":"java NIO相关(五) 分散(Scatter) 和聚集(Gather)","date":"2020-05-16T17:20:10.000Z","updated":"2021-05-04T06:31:15.745Z","comments":true,"path":"2020/05/17/java NIO相关(五) 分散(Scatter) 和聚集(Gather)/","link":"","permalink":"https://dengchuncui.github.io/2020/05/17/java%20NIO%E7%9B%B8%E5%85%B3(%E4%BA%94)%20%E5%88%86%E6%95%A3(Scatter)%20%E5%92%8C%E8%81%9A%E9%9B%86(Gather)/","excerpt":"分散(Scatter) 和聚集(Gather)分散读取(scattering reads) 是从channel中读取的数据“分散”到多个buffer中","text":"分散(Scatter) 和聚集(Gather)分散读取(scattering reads) 是从channel中读取的数据“分散”到多个buffer中 注意:按照缓冲区的顺序,写入position 和limit 之间的数据到channel 分散读取将通道中的数据分散到多个缓冲区中 聚集写入将多个缓冲区中的数据聚集到通道中","categories":[{"name":"NIO 系列","slug":"NIO-系列","permalink":"https://dengchuncui.github.io/categories/NIO-%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"}]},{"title":"java NIO 相关(四) 通道 channel","slug":"java NIO相关(四) 通道 channel","date":"2020-05-15T13:11:11.000Z","updated":"2021-05-04T06:30:55.990Z","comments":true,"path":"2020/05/15/java NIO相关(四) 通道 channel/","link":"","permalink":"https://dengchuncui.github.io/2020/05/15/java%20NIO%E7%9B%B8%E5%85%B3(%E5%9B%9B)%20%E9%80%9A%E9%81%93%20channel/","excerpt":"channel 介绍通道(channel) :由java.nio.channels包定义的,channel 表示IO源与目标打开的连接 。Channel 类似于传统的流,只不过channel 本身不能直接访问数据,channel 只能与buffer进行交互","text":"channel 介绍通道(channel) :由java.nio.channels包定义的,channel 表示IO源与目标打开的连接 。Channel 类似于传统的流,只不过channel 本身不能直接访问数据,channel 只能与buffer进行交互 一、通道(channel)用于源节点与目标节点的连接，在java nio中负责缓冲区数据的传输。channel本身不存储数据，因此需要配合缓冲区进行传输。 流与通道的区别1、流是单向的，通道是双向的，可读可写。2、流读写是阻塞的，通道可以异步读写。3、流中的数据可以选择性的先读到缓存中，通道的数据总是要先读到一个缓存中，或从缓 存中写入 二、通道的主要实现类Java.nio.channels.Channel接口 |–FileChannel |–SocketChannel |–ServerSocetChannel |–DataramChannel 三、获取通道JAVA针对支持通道的类提供了getChannel()方法 本地IO FileInputStream/FileOutputStream RamdomAccessFile 网络IO Socket ServerSocket DatagramSocket 在JDK1.7中的NIO.2 针对各个通道提供了静态方法open() 在JDK1.7中的Files工具类的newByteChannel() 四、非直接缓冲区使用channel的dome12345678910111213141516171819202122232425262728293031323334353637public static void main(String[] args) &#123; FileInputStream fis &#x3D; null; FileOutputStream fos &#x3D; null; &#x2F;&#x2F;nio 文件复制 try &#123; fis &#x3D; new FileInputStream(&quot;C:\\\\Users\\\\12113\\\\Desktop\\\\1.html&quot;); fos &#x3D; new FileOutputStream(&quot;C:\\\\Users\\\\12113\\\\Desktop\\\\nio.html&quot;); FileChannel fosChannel &#x3D; fos.getChannel(); FileChannel fisChannel &#x3D; fis.getChannel(); ByteBuffer buffer &#x3D;ByteBuffer.allocate(1024); while (fisChannel.read(buffer)!&#x3D;-1)&#123; buffer.flip(); &#x2F;&#x2F;写模式 fosChannel.write(buffer); buffer.clear(); &#125; &#125; catch (FileNotFoundException e) &#123; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; 五、直接缓冲区使用channel123456789101112131415161718192021222324public static void main(String[] args) throws IOException &#123; FileChannel fileInChannel &#x3D; FileChannel.open(Paths.get(&quot;C:\\\\Users\\\\12113\\\\Desktop\\\\temp.txt&quot;), StandardOpenOption.READ); FileChannel fileOutChannel &#x3D; FileChannel.open(Paths.get(&quot;C:\\\\Users\\\\12113\\\\Desktop\\\\nio3.txt&quot;), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE_NEW); MappedByteBuffer inByteBuffer &#x3D; fileInChannel.map(MapMode.READ_ONLY, 0, fileInChannel.size()); MappedByteBuffer outByteBuffer &#x3D; fileOutChannel.map(MapMode.READ_WRITE, 0, fileInChannel.size()); byte[] dest &#x3D;new byte[inByteBuffer.limit()]; inByteBuffer.get(dest); outByteBuffer.put(dest); &#125;&#x2F;&#x2F;通道之间传输 fileInChannel.transferTo(0,fileInChannel.size(),fileOutChannel); &#125; 六、channel 的数据传输transferTo() transferFrom() 七、图解channelChannel是一个独立的处理器，专门用于IO操作，附属于CPU。在提出IO请求的时候，CPU不需要进行干预，也就提高了效率。","categories":[{"name":"NIO 系列","slug":"NIO-系列","permalink":"https://dengchuncui.github.io/categories/NIO-%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"}]},{"title":"java NIO 相关(三) NIO 直接缓冲区和非直接缓冲区","slug":"java NIO相关(三) NIO 直接缓冲区和非直接缓冲区","date":"2020-05-01T10:11:11.000Z","updated":"2021-05-04T06:30:40.066Z","comments":true,"path":"2020/05/01/java NIO相关(三) NIO 直接缓冲区和非直接缓冲区/","link":"","permalink":"https://dengchuncui.github.io/2020/05/01/java%20NIO%E7%9B%B8%E5%85%B3(%E4%B8%89)%20NIO%20%E7%9B%B4%E6%8E%A5%E7%BC%93%E5%86%B2%E5%8C%BA%E5%92%8C%E9%9D%9E%E7%9B%B4%E6%8E%A5%E7%BC%93%E5%86%B2%E5%8C%BA/","excerpt":"非直接缓冲区通过allocate() 方法分配缓冲区,将缓冲区建立在jvm的内存直接与非直接缓冲区字节缓冲区要么是直接的，要么是非直接的·如果为直接字节缓冲区·则Java虐拟机会尽最大努力直接在此缓冲区上执行本机|/0操作·也就是说，在每次调用基础操作系统的一个本机1/0操作之前（或之后），虐拟机都会尽量避免将缓冲区的内容复制到中间缓冲区巾（或从中间缓冲区中复制内容）。","text":"非直接缓冲区通过allocate() 方法分配缓冲区,将缓冲区建立在jvm的内存直接与非直接缓冲区字节缓冲区要么是直接的，要么是非直接的·如果为直接字节缓冲区·则Java虐拟机会尽最大努力直接在此缓冲区上执行本机|/0操作·也就是说，在每次调用基础操作系统的一个本机1/0操作之前（或之后），虐拟机都会尽量避免将缓冲区的内容复制到中间缓冲区巾（或从中间缓冲区中复制内容）。 直接缓冲区通过allocateDirect() 方法分配直接缓冲区,将缓冲区建立在物理内存中，可以提高效率 直接字节缓冲区可以通过调用此类的allocateDirect()工厂方法来创建·此方法返回的缓冲区透行分配和取消分配所需成本通常于非直接缓冲区·直接缓冲区的内容可以驻留在常規的垃圾回收堆之外·因此．它们对应用程序的内存需求量造成的影响可能并不明显。所以，建议将直接缓冲区主要分配给那些易受基础系统的本机|/0操作影响的大型、持久的缓冲区·一情况下，最好舣在直接缓冲区能在程序性能方面帚来明显好处时分配它们 直接字节缓冲区还可以通过FileChanneI的map()方法将文件区域直接暌射到内存中来创建·该方法返回MappedByteBuffer·Java平台的实现有助于通过JNI从本机代码创建直接字节缓冲区·如果以上这些缓冲区中的某个缓冲区实蚪指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或鞘后的某时间导致出不定的异常·字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其isDirect()方法来确定．供此方法是为了能够在性能关键型代码中挾行显式缓冲区管理· 图解直接缓冲区和非直接缓冲区 源码分析 直接缓冲区 12345678910111213141516171819202122232425public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity); &#125; HeapByteBuffer(int cap, int lim) &#123; &#x2F;&#x2F; package-private super(-1, 0, lim, cap, new byte[cap], 0); &#x2F;* hb &#x3D; new byte[cap]; offset &#x3D; 0; *&#x2F; &#125; 可以看到直接在堆中创建空间也就是数组 非直接缓冲区public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); } DirectByteBuffer(int cap) { // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null; &#125; 可以看到是根据 VM.isDirectMemoryPageAligned() 方法直接调用了内存分,让操作系统开辟缓存空间 DirectByteBuffer(堆外内存)DirectByteBuffer 继承自 MappedByteBuffer，它们都是使用的堆外内存，不受 JVM 堆大小的 限制，只是前者仅仅是分配内存，后者是将文件映射到内存中。可以通过 ByteBuf.allocateDirect 方法获取 堆外内存的特点(大对象;加快内存拷贝;减轻 GC 压力) 对于大内存有良好的伸缩性(支持分配大块内存) 对垃圾回收停顿的改善可以明显感觉到(堆外内存，减少 GC 对堆内存回收的压力) 在进程间可以共享，减少虚拟机间的复制，加快复制速度(减少堆内内存拷贝到堆外内存的过程) 还可以使用 池+堆外内存 的组合方式，来对生命周期较短，但涉及到 I/O 操作的对象进行堆外内存的再使用。( Netty 中就使用了该方式 ) 堆外内存的一些问题 堆外内存回收问题(不手工回收会导致内存溢出，手工回收就失去了 Java 的优势); 数据结构变得有些别扭。要么就是需要一个简单的数据结构以便于直接映射到堆外内存， 要么就使用复杂的数据结构并序列化及反序列化到内存中。很明显使用序列化的话会比较头 疼且存在性能瓶颈。使用序列化比使用堆对象的性能还差。 堆外内存的释放 java.nio.DirectByteBuffer 对象在创建过程中会先通过 Unsafe 接口直接通过 os::malloc 来分配 内存，然后将内存的起始地址和大小存到 java.nio.DirectByteBuffer 对象里，这样就可以直接 操作这些内存。这些内存只有在 DirectByteBuffer 回收掉之后才有机会被回收，因此如果这 些对象大部分都移到了 old，但是一直没有触发 CMS GC 或者 Full GC，那么悲剧将会发生， 因为你的物理内存被他们耗尽了，因此为了避免这种悲剧的发生，通过 -XX:MaxDirectMemorySize 来指定最大的堆外内存大小，当使用达到了阈值的时候将调用 System.gc 来做一次 full gc，以此来回收掉没有被使用的堆外内存。 GC 方式:存在于堆内的 DirectByteBuffer 对象很小，只存着基地址和大小等几个属性，和一个 Cleaner， 但它代表着后面所分配的一大段内存，是所谓的冰山对象。通过前面说的 Cleaner，堆内的 DirectByteBuffer 对象被 GC 时，它背后的堆外内存也会被回收。当新生代满了，就会发生 minor gc;如果此时对象还没失效，就不会被回收;撑过几次 minorgc 后，对象被迁移到老生代;当老生代也满了，就会发生 full gc。 这里可以看到一种尴尬的情况，因为 DirectByteBuffer 本身的个头很小，只要熬过了 minor gc， 即使已经失效了也能在老生代里舒服的呆着，不容易把老生代撑爆触发 full gc，如果没有别 的大块头进入老生代触发 full gc，就一直在那耗着，占着一大片堆外内存不释放。这时，就只能靠前面提到的申请额度超限时触发的 System.gc()来救场了。但这道最后的保 险其实也不很好，首先它会中断整个进程，然后它让当前线程睡了整整一百毫秒，而且如果 gc 没在一百毫秒内完成，它仍然会无情的抛出 OOM 异常。那为什么 System.gc()会释放 DirectByteBuffer 呢?每个 DirectByteBuffer 关联着其对应的 Cleaner，Cleaner 是 PhantomReference 的子类，虚 引用主要被用来跟踪对象被垃圾回收的状态，通过查看 ReferenceQueue 中是否包含对象所 对应的虚引用来判断它是否即将被垃圾回收。当GC时发现DirectByteBuffer除了PhantomReference外已不可达，就会把它放进 Reference 类 pending list 静态变量里。然后另有一条 ReferenceHandler 线程，名字叫 “Reference Handler”的，关注着这个 pending list，如果看到有对象类型是 Cleaner，就会执行它的 clean()， 其他类型就放入应用构造 Reference 时传入的 ReferenceQueue 中，这样应用的代码可以从 Queue 里拖出这些理论上已死的对象，做爱做的事情——这是一种比 finalizer 更轻量更好的 机制。手工方式:如果想立即释放掉一个 MappedByteBuffer/DirectByteBuffer，因为 JDK 没有提供公开 API， 只能使用反射的方法去 unmap;或者使用 Cleaner 的 clean 方法。","categories":[{"name":"NIO 系列","slug":"NIO-系列","permalink":"https://dengchuncui.github.io/categories/NIO-%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"}]},{"title":"java NIO 相关(二) 缓冲区buffer的数据存取","slug":"java NIO相关(二) 缓冲区buffer的数据存取","date":"2020-04-13T10:15:41.000Z","updated":"2021-05-04T06:29:53.564Z","comments":true,"path":"2020/04/13/java NIO相关(二) 缓冲区buffer的数据存取/","link":"","permalink":"https://dengchuncui.github.io/2020/04/13/java%20NIO%E7%9B%B8%E5%85%B3(%E4%BA%8C)%20%E7%BC%93%E5%86%B2%E5%8C%BAbuffer%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AD%98%E5%8F%96/","excerpt":"简介 java nio 是jdk1.4引入的,其中包含 selector,channel,buffer 其中buffer是用来提高效率的。nio中操作数据,都是直接操作buffer对象","text":"简介 java nio 是jdk1.4引入的,其中包含 selector,channel,buffer 其中buffer是用来提高效率的。nio中操作数据,都是直接操作buffer对象 buffer的类型 ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer java基本类型除了boolean外都有对应的buffer的对象，都是使用allocate()方法创建对应的buffer对象 Buffer 的相关属性 capacity 容量用来定义buffer的容量，在buffer初始化的时候设置,不可被修改 limit 界限 buffer的上限位置,limit &lt;= capacity pasition 位置 读写buffer的时候,下一个写或者读的位置 pasition小于 limit mark 标记位置 使用mark()方法标记的位置,当调用reset()方法时,将pasition指向mark的位置 buffer 初始化 buffer 初始化调用 allocate()方法创建,下面看一下源码 12345public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity);&#125; 可以看到 使用 new HeapByteBuffer(capacity, capacity); 在jvm堆中创建一个buffer对象 123456789101112Buffer(int mark, int pos, int lim, int cap) &#123; if (cap &lt; 0) throw new IllegalArgumentException(&quot;Negative capacity: &quot; + cap); this.capacity &#x3D; cap; limit(lim); position(pos); if (mark &gt;&#x3D; 0) &#123; if (mark &gt; pos) throw new IllegalArgumentException(&quot;mark &gt; position: (&quot;+ mark + &quot; &gt; &quot; + pos +&quot;)&quot;); this.mark &#x3D; mark; &#125; &#125; 当初始化Bytebuffer后实际的buffer对象的相关属性情况如下。 Buffer的核心方法 get()123456789public byte get() &#123; return hb[ix(nextGetIndex())];&#125;final int nextGetIndex() &#123; if (position &gt;&#x3D; limit) throw new BufferUnderflowException(); return position++;&#125; put()12345678910public ByteBuffer put(byte x) &#123; hb[ix(nextPutIndex())] &#x3D; x; return this;&#125;final int nextPutIndex() &#123; if (position &gt;&#x3D; limit) throw new BufferOverflowException(); return position++;&#125; 比如put a,b,c,d 到buffer中实际的存储情况是这样的每次put的时候position 都指向后一位 flip()上图我们将a,b,c,d 加入到buffer后。当我们调用get()方法的时候是获取不到数据的,因为position是5调用get方法获取不到数据。 所以我们想获取数据,需要将position重新设置为0 查看get()源码,我们发现position &gt;= limit才会抛出异常。所以我们还需要设置limit到5,需要两部操作。而flip()方法是将上面两个操作和成一个方法。执行的结果如下 Rewind()我们指向将position恢复到0,不影响limit,可以调用这个方法。 Clear()调用clear方法,会将position设置到0,limit设置到capatity在数组中真是的数据是没有被删除的。后续的put操作会覆盖原来的数据。 Mark()标记,表示记录到当前position 的位置可以通过reset()恢复到mark()标记位置 hasremaining()判断缓冲区中是否还有剩余数据 Remaining()获取缓冲区还可以操作的数据","categories":[{"name":"NIO 系列","slug":"NIO-系列","permalink":"https://dengchuncui.github.io/categories/NIO-%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"}]},{"title":"java NIO 相关(一) NIO介绍","slug":"java NIO 相关(一) NIO介绍","date":"2020-03-25T03:05:48.000Z","updated":"2021-05-04T06:29:22.779Z","comments":true,"path":"2020/03/25/java NIO 相关(一) NIO介绍/","link":"","permalink":"https://dengchuncui.github.io/2020/03/25/java%20NIO%20%E7%9B%B8%E5%85%B3(%E4%B8%80)%20NIO%E4%BB%8B%E7%BB%8D/","excerpt":"Java NIO简介 Java nio (new io) 是从java 1.4 版本开始引入有的一个新的IO API 可以替代标准的java io API. NIO 和原来的io有同样的作用和目的,但是使用方式完全不通，NIO支持面向缓存区的基于通道的IO操作,NIO将以更加高效的方式进行文件的读写操作。","text":"Java NIO简介 Java nio (new io) 是从java 1.4 版本开始引入有的一个新的IO API 可以替代标准的java io API. NIO 和原来的io有同样的作用和目的,但是使用方式完全不通，NIO支持面向缓存区的基于通道的IO操作,NIO将以更加高效的方式进行文件的读写操作。 |io|nio| |-------|-------| |面向流|面向缓冲区| |阻塞io|同步非阻塞io| |无|selector选择器 ### 通道和缓冲区 Java nio 系统的核心在于：通道(channel) 和缓冲区(buffer) 通道表示打开到IO设备(例如:文件、套接字)的连接,若需要使用NIO,需要获取用于连接IO的通道以及用于容纳数据的缓冲区,然后操作缓冲区,对数据进行处理。 1. 先建立通道 2. 创建缓冲区 3. 操作缓冲区 ### io 输入流的读取数据逻辑 1. io读取数据 - 打开一个io流 - 循环 - 读取数据 - 关闭io流 2. io写入数据 - 打开一个io流 - 循环 - 写入取数据 - 关闭io流 ### 相关概念 - Java.io 中最为核心的一个概念就是流，面向流的编程，一个流要么是输入流要么是输出流，不可能同时即是输出流又是输出流 Java.nio中拥有3个概念 selector channel 和 buffer 在java.nio中我们是面向块(blocl)或是缓冲区(buffer)编程的 buffer本事就是一个堆存区域地址是线上他就是一个数组，数据的读和写都是通过buffer来实现的 除了数组之外，buffer还提供了对于数据的结构化访问方式，并且可以追踪到系统的读写过程 java中的8种原生数据类型都有各自对应的buffer类型 如intbuffer longbuffer bytebuffer charbuffer boolean除外 Channel 指的是可以向其写入数据或是从中读取数据对象，它类似于 java中的stream 所有数据的读写都是通过buffer来进行的，永远不过出现直接向channel写入数据的情况，或是直接从channel读取数据的情况 与stream不同的是 channel是双向的 一个流只可能是inputstream 或是outputstream,channel打开后可以进行读取写入或是读写 由于channel是双向的因此他能更好的放映出操作系统的真实情况，在linux系统中底层操作系统的通道就是双向的 java io 和 nio的区别","categories":[{"name":"NIO 系列","slug":"NIO-系列","permalink":"https://dengchuncui.github.io/categories/NIO-%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"}]},{"title":"java IO相关(二) BIO NIO AIO 介绍","slug":" java IO相关(二) BIO NIO AIO 介绍","date":"2020-03-20T10:01:48.000Z","updated":"2021-05-04T06:31:57.102Z","comments":true,"path":"2020/03/20/ java IO相关(二) BIO NIO AIO 介绍/","link":"","permalink":"https://dengchuncui.github.io/2020/03/20/%20java%20IO%E7%9B%B8%E5%85%B3(%E4%BA%8C)%20BIO%20NIO%20AIO%20%E4%BB%8B%E7%BB%8D/","excerpt":"BIObio 同步阻塞,每一个请求连接都由一个线程来处理 NIOnio 同步非阻塞,多路复用器轮询客户端的请求，每个客户端的 IO 请求会对应服务器的 一个线程","text":"BIObio 同步阻塞,每一个请求连接都由一个线程来处理 NIOnio 同步非阻塞,多路复用器轮询客户端的请求，每个客户端的 IO 请求会对应服务器的 一个线程 AIOaio 异步非阻塞,客户端的io请求都是由os来处理,os处理完成后再通知服务器启动线程处理 （需要操作系统支持） 进程向操作系统请求数据 操作系统把外部数据加载到内核的缓冲区中 操作系统把内核的缓冲区拷贝到进程的缓冲区 进程获得数据完成自己的功能 Java NIO 属于同步非阻塞 IO，即 IO 多路复用，单个线程可以支持多个 IO 即询问时从 IO 没有完毕时直接阻塞，变成了立即返回一个是否完成 IO 的信号。异步 IO 就是指 AIO，AIO 需要操作系统支持。","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"IO","slug":"IO","permalink":"https://dengchuncui.github.io/tags/IO/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"}]},{"title":"java IO相关(一) unix的五种模型","slug":" java IO相关(一) unix的五种模型","date":"2020-03-19T03:05:48.000Z","updated":"2021-05-04T06:18:06.875Z","comments":true,"path":"2020/03/19/ java IO相关(一) unix的五种模型/","link":"","permalink":"https://dengchuncui.github.io/2020/03/19/%20java%20IO%E7%9B%B8%E5%85%B3(%E4%B8%80)%20unix%E7%9A%84%E4%BA%94%E7%A7%8D%E6%A8%A1%E5%9E%8B/","excerpt":"Uinx IO 模型 unix 的io 模型分为以下5类 阻塞io 当用户发起io请求后,等待数据,程序将数据从内核复制到程序缓冲区中,整个操作都是阻塞状态。","text":"Uinx IO 模型 unix 的io 模型分为以下5类 阻塞io 当用户发起io请求后,等待数据,程序将数据从内核复制到程序缓冲区中,整个操作都是阻塞状态。 非阻塞io 当用户发起请求后,不等待数据,而是返回一个数据未准备完成的标志。 操作系统内核将准备要操作的数据,这个过程中程序会轮训的请求操作,直到操作系统将数据准备好。当程序轮训到系统内核响应数据准备好了之后,程序再将数据复制到程序自身的缓冲区 io复用模型 我们常用select和poll函数使用了io复用模型。 当用户调用select函数的时候会阻塞,select函数会系统调用操作内核进行数据报的准备工作。当数据报准备完成后,程序直接复制数据包的内容到程序缓冲区中,io复用现在看来和阻塞io没有什么区别。但是当用户比较多的时候优势就展现出来了，假设有100个用户阻塞io会阻塞100个进程处理io.如果是io复用模型,则用1个线程去管理这100个io请求。 信号驱动io我们可以使用信号.当用户发起io请求后,使程序接受操作系统的信号通知。不等待数据。此时操作系统进行数据报的准备，当数据报准备完成之后会以信号的方式通知程序。程序收到数据准备完成的信号通知后，在将数据复制到程序缓冲区中。 异步io当用户发起请求后不等待数据,操作系统内核直接将数据复制到程序的缓存区中，等到复制完成之后在通知程序操作成功。 总结前四种io模型都属于同步io，其中的第二阶段相同，都属于数据报准备完成后，操作系统内核将数据复制到程序的缓存区中。 阻塞io则在数据准备和数据准备完成一直处于阻塞中 非阻塞io则是轮训的方式一直请求操作系统内核数据报是否准备完成 多路复用io则是发起io请求后,调用select。select单线程来判断那个io请求的数据报是否准备好。然后系统直接调用。 信号io则是 操作系统内核在数据报准备好的时候以信号的方式通知程序 异步io全程都是操作系统进行io处理，在处理io结束后通知程序 异步非异步的区别是io操作过程是否由操作系统处理。 阻塞非阻塞是io操作，操作系统是否返回一个标志告知io操作是否完成 相关博客Unix下 五种 I/O模型 图解UNIX的I/O模型","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"IO","slug":"IO","permalink":"https://dengchuncui.github.io/tags/IO/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"}]},{"title":"java 基础知识点整理(三)","slug":" java 基础知识点整理(三)","date":"2020-03-11T05:05:48.000Z","updated":"2021-05-04T06:14:38.749Z","comments":true,"path":"2020/03/11/ java 基础知识点整理(三)/","link":"","permalink":"https://dengchuncui.github.io/2020/03/11/%20java%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86(%E4%B8%89)/","excerpt":"(1) 枚举的jdk实现 下面是枚举代码 1234567891011121314public enum Labels0 &#123; ENVIRONMENT(&quot;环保&quot;), TRAFFIC(&quot;交通&quot;), PHONE(&quot;手机&quot;); private String name; private Labels0(String name) &#123; this.name &#x3D; name;&#125;public String getName() &#123; return name; &#125; &#125;","text":"(1) 枚举的jdk实现 下面是枚举代码 1234567891011121314public enum Labels0 &#123; ENVIRONMENT(&quot;环保&quot;), TRAFFIC(&quot;交通&quot;), PHONE(&quot;手机&quot;); private String name; private Labels0(String name) &#123; this.name &#x3D; name;&#125;public String getName() &#123; return name; &#125; &#125; 在编译后生成的字节码如下:可以看到枚举被编译后就是一个类，被编辑为final并且继承Enum里面的枚举都是static finak的常量，静态的所以是单例的重点：++枚举类型没有可以访问的构造器，是真正的 final;是实例受控的，它们是单例的泛型化; 本质上是单元素的枚举;提供了编译时的类型安全。 单元素的枚举是实现单例的最佳方法!++ (2) jdk序列化 定义：将实现Serializable接口的对象转成一个字节数组,并且可以讲字节数组转换为对象 实现序列化 实现Serializable接口 该接口只是一个可序列化的标志并没包含实际的属性和方法 如果不在该方法中添加readObject 和 writeObject 则采取默认的序列化机制，如果添加了这两个方法还想执行默认的序列化机制 则需要分别调用 defaultReadObject()和defaultWriteObject()方法 为了保障安全性可以使用transient关键字修饰不必序列化的属性因为在序列化的过程中private的属性也会被序列化 实现ExternalSerializable接口 可以对要求序列化的内容进行控制，控制那些属性能被序列化，那些不能被序列化 反序列化 实现Serializable接口接口反序列化,无需调用构造方法，完全处于字节 实现ExternalSerializable接口方法在反序列化的时候调用构造方法 注意事项 被static 修饰的对象不会被序列化 对象的类名 属性都会被序列化，方法不会被序列化 保证序列化对象对象所在类的属性也是可以被序列化的 ObjectOutputStream 是专门用来输出对象的输出流;ObjectOutputStream 将 Java 对象写入 OutputStream。可以使用 ObjectInputStream 读取 (重构)对象。 serialVersionUID用来判断序列化的版本号的，如果反序列化的时候如果版本号不一致则会抛异常 (3)ERROR 和 Exception error 是程序无法处理的错误，是有jvm虚拟机器抛出的异常如。outofmemorayerror,虚拟机将发生这种异常的线程直接终止 exception 是可以程序可以处理的异常，是程序主动抛出的异常。异常氛围检查时异常和非检查异常，检查异常需要try cache 非检查异常无需try cache (4)常见的RuntimeException NullPointerExcepiton 空指针 IllegalArgumentExcepiton 参数无效 ArraysOutOfBoundsExcepiton 数组越界 ClassCaseException 类型转换异常 NumberFormatException 数字转换异常 (5)泛型擦除 编辑器生成的字节码是不包含泛型信息的,编译过程中会擦除泛型。限定类型会指向限定类型，非限定类型则指向object","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"源码","slug":"源码","permalink":"https://dengchuncui.github.io/tags/%E6%BA%90%E7%A0%81/"}]},{"title":"java 基础知识点整理(二)","slug":" java 基础知识点整理(二)","date":"2020-03-07T04:05:48.000Z","updated":"2021-05-04T06:14:26.211Z","comments":true,"path":"2020/03/07/ java 基础知识点整理(二)/","link":"","permalink":"https://dengchuncui.github.io/2020/03/07/%20java%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86(%E4%BA%8C)/","excerpt":"(1) 抽象类和接口区别： 抽象类可以有的方法可以有普通方法，接口的方法全都是抽象方法 抽象类可以用普通成员变量,接口中只有常量也就是，static final的 抽象类是单继承,接口可以多继承","text":"(1) 抽象类和接口区别： 抽象类可以有的方法可以有普通方法，接口的方法全都是抽象方法 抽象类可以用普通成员变量,接口中只有常量也就是，static final的 抽象类是单继承,接口可以多继承 (2) 面向对象的三大特性 封装 将对象属性封装起来，只提供相关方法保障对象安全性,隐藏细节性。 继承代码复用,增加扩展性 多态允许对象的不通子类对一个方法作出多种实现。 多态的三个条件，继承,子类重写夫类的方法,父类的引用只想子类的实现 (3) 重写和重载 重写 子类重写夫类的方法,根据子类的类型调用具体的方法 重载在同类下，方法名相同，参数数量不同 (4) ThreadLocal(线程局部变量) 线程之间共享变量是有风险的,如果想每一个线程使用自己的变量可以使用ThreadLocal来实现 ThreadLocal 实际上是使用 ThreadLocalMap 来实现的 key 存储的是ThreadLocal,value为当前线程存储的变量 因为线程都有一个ThreadLocalMap 的属性。 1. set方法 (1) 获取当前线程 (2) 从当前线程获取ThreadLocalMap对象 (3) 把ThreadLoacl对象作为key value为要存储的值 (4) 如果获取当前线程ThreadLocalMap 为空 则创建ThreadLocalMap 12345678 public void set(T value) &#123; Thread t &#x3D; Thread.currentThread(); ThreadLocalMap map &#x3D; getMap(t); if (map !&#x3D; null) map.set(this, value); else createMap(t, value);&#125; 2. get方法 (1) 获取当前线程 (2) 从当前线程获取ThreadLocalMap,将当前的ThreadLocal作为key 获取对应的value值 public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; (5) ThreadLocalMap的key为什么是弱引用？ 如果不是弱引用则ThreadLocalMap无法释放内存 1. 如果是普通的Map用来存储，theadlocal一直与线程保持强引用的关系 2. 会导致gc时如果线程不结束，则无法进行垃圾回收(gc 垃圾回收是可达性判断,强引用的关系是无法进行gc)的 3. ThreadLocalMap 的key 为弱引用 继承了Weakreference来实现的 4. ThreadLocalMap 为垃圾回收实现了便利 123456789&#x2F;&#x2F; ThreadLocalMap的key static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; &#x2F;** The value associated with this ThreadLocal. *&#x2F; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value &#x3D; v; &#125; &#125; (6) ThreadLocal 内存泄漏 只有调用ThreadLocal的get set remove方法才会采取措施来进行处理 ThreadLocal对应的value， 如果在局部定义ThreadLocal但是没有显示的调用remove方法怎会产生内存泄漏。 因为在 set或get方法的时候会将key为null的对象去除这样，对应的value没有gc root了,则会被gc回收 jdk建议将ThreadLocal定义为 static final的 这样 它的声明周期更长,由于一直都存在强引用，这样就能保证在任何时候都能获取到对应 Entry的value值，然后remove它，防止内存泄露。 (7) Comparable 和 Comparator的区别 Comparable 是接口 Coparator是类 需要排序的类都实现了Comparable 并且重写了 compare方法this.==obj 结果0this.&gt; obj 结果正数this.&lt; obj 结果负数 Comparator 可以传入到排序集合工具类的sort方法进行控制(8) 继承 子类继承父类所有成员变量 (private 成员只有拥有权没有访问权) 子类可以直接使用父类的非private的成员隐式使用则在编译期间自动加上super关键字 (9) fianl 相关 final 修饰类 ,类不能被继承 如String final 修饰方法,方法不能被重写,重载 final 修饰属性,属性不可变 常量 (10) try{}cache{}finaly return 在 try {} 中return 会执行finaly的逻辑 在 try {} 中return 并且 finaly 也有retrun 返回的是try {} 中return 的值,retrun的时候是直接将retrun的值放到临时保存到局部变量中,等到finaly执行结束后会直接从该位置的值直接返回 无论执行return break continue 都会执行 finaly的内容，除非调System.exist() (11) switch字符串的实现switch的字符串的实现原理是int,在编译后switch的字符串会变为hashcode的值","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"}]},{"title":"java 基础知识点整理(一)","slug":" java 基础知识点整理(一)","date":"2020-03-04T07:05:48.000Z","updated":"2021-05-04T06:14:45.072Z","comments":true,"path":"2020/03/04/ java 基础知识点整理(一)/","link":"","permalink":"https://dengchuncui.github.io/2020/03/04/%20java%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86(%E4%B8%80)/","excerpt":"（1）JDK &amp; JRE &amp; JVM 的关系 JDKJDK包含jre、java开发工具、java核心类库 JREjre是运行java程序的环境，包含java核心类库,和jvn的标准实现 JVM是java虚拟机，实现java跨平台最核心的部分","text":"（1）JDK &amp; JRE &amp; JVM 的关系 JDKJDK包含jre、java开发工具、java核心类库 JREjre是运行java程序的环境，包含java核心类库,和jvn的标准实现 JVM是java虚拟机，实现java跨平台最核心的部分 （2）跨平台 因为jvm运行的是java编译后的字节码文件,因为jvm可以在多个平台安装,所以字节码文件就可以在多个平台的jvm上面运行.从而实现一次编译到处运行 （3）基础数据类型 整型： byte、short、int、long 浮点型：double、float 逻辑型：boolean 字符型：char 长度 byte(1) 2的-7次方 到2的7次方-1 short(2) 2的-15次方 到 2的 15 次方-1 int(4) long(8) double(8) float(4) boolean(1/8) char(2) （4）自动装箱，自动拆箱 自动装箱： 1Integer i&#x3D; 100； &#x2F;&#x2F; 基本类型自动装箱为包装类,编译器会优化为 Integer i &#x3D; new Integer(100); 自动拆箱 1int i &#x3D;new Integer(100); &#x2F;&#x2F;编译集会优化为 int i &#x3D;new Integer(100).intValue(); (5) Integer.intValue()integer 定义的对象,范围在-128带127会被缓存起来，所以在这个范围内的integer进行判断相等会等于true，因为是同一对象 (6) == 和 equals 的区别1.== 是判断对象地址是否相等，equals没在重写的情况下也是判读对象地址等同于==2.不通对象的地址是不一样的，如果相比较两个对象的内容是否一样则需重写equals方法 (7）hashcode()和 equals()的区别 equals()必须满足一下几点：1.自反性 a.equals(a) =true2.对称性 a.equals(b) =true b.equals(a) =true3.一致性 a.equals(a) 多次调用永远等于true4.对于null判断始终等于falsehashcode()的实现方式和操作系统有关,姑且认为是获取对象的地址。重写equals()方法必须重写hashcode(),因为在hash数据结构添加数据的时候，需要先通过hashcode()方法查找存储的位置(链地址发),如果该位置不存在则插入，如果该位置已经拥有对象则,需要通过equals()方法判断对象是否相同，如果相同则替换，如果不通则在改对象后面进行存储。1.两个相同的对象hashcode 必须相同,hashcode相同的对象,对象之间可能不通 2. hashcode()不同,则对象也不相同 如果之重写了equals()方法会出现什么效果？答案：两个相同的对象hashcode不同,hashmap的key会放入相同的对象 (8) String &amp; StringBuffer &amp; StringBuilder 都是final的不可以被继承 String 不可变 StringBuffer,StringBuilder 长度可变 String 重写了equals()方法和hashcode()方法 StringBuffer 是线程安全的 StringBuilder是线程不安全的 在单线程下 StringBuffer和StringBuilder效率一样,再多线程下StringBuilder效率更高,因为StringBuffer在一些方法上加了同步synchronized 方式 字面直接声明的String 在编译期间都会优化为final声明的 (9) ‘+’ 和substring() ‘+’ 和 substring() 都会生成一个新的对象 ‘+’ 和 substring() 都是在在堆中生成的对象 (没有在常量池所以不共享) ‘+’ 在编译期间会被优化为 append()方法 (10) 可以手动创建java.long.String 类么？可以使用么？为什么？ 可以创建，但是不能被使用，因为类加载机制(双亲委派机制) 因为自定义的类的加载器为AppClassLoader.AppClassLoader加载器加载的时候需要先加载其父加载器,ExtClassLoader加载器,ExtClassLoader会在 jre/lib/ext 下去寻找 java.long.String 类, 此时找不到该类，则会调用ExtClassLoader的父加载器BootStrap加载器,在jre/lib下寻找,最终找到String类并且加载 这也就是类加载的委托机制","categories":[{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"}]}],"categories":[{"name":"大数据","slug":"大数据","permalink":"https://dengchuncui.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"项目规范","slug":"项目规范","permalink":"https://dengchuncui.github.io/categories/%E9%A1%B9%E7%9B%AE%E8%A7%84%E8%8C%83/"},{"name":"java","slug":"java","permalink":"https://dengchuncui.github.io/categories/java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"NIO 系列","slug":"NIO-系列","permalink":"https://dengchuncui.github.io/categories/NIO-%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://dengchuncui.github.io/tags/Hadoop/"},{"name":"计算存储分离","slug":"计算存储分离","permalink":"https://dengchuncui.github.io/tags/%E8%AE%A1%E7%AE%97%E5%AD%98%E5%82%A8%E5%88%86%E7%A6%BB/"},{"name":"云原生","slug":"云原生","permalink":"https://dengchuncui.github.io/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"源码","slug":"源码","permalink":"https://dengchuncui.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"datax","slug":"datax","permalink":"https://dengchuncui.github.io/tags/datax/"},{"name":"数据同步","slug":"数据同步","permalink":"https://dengchuncui.github.io/tags/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"},{"name":"大数据","slug":"大数据","permalink":"https://dengchuncui.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"项目规范","slug":"项目规范","permalink":"https://dengchuncui.github.io/tags/%E9%A1%B9%E7%9B%AE%E8%A7%84%E8%8C%83/"},{"name":"错误码","slug":"错误码","permalink":"https://dengchuncui.github.io/tags/%E9%94%99%E8%AF%AF%E7%A0%81/"},{"name":"java基础","slug":"java基础","permalink":"https://dengchuncui.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"hashmap","slug":"hashmap","permalink":"https://dengchuncui.github.io/tags/hashmap/"},{"name":"设计模式","slug":"设计模式","permalink":"https://dengchuncui.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"静态代理","slug":"静态代理","permalink":"https://dengchuncui.github.io/tags/%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"NIO","slug":"NIO","permalink":"https://dengchuncui.github.io/tags/NIO/"},{"name":"字符集","slug":"字符集","permalink":"https://dengchuncui.github.io/tags/%E5%AD%97%E7%AC%A6%E9%9B%86/"},{"name":"utf-8","slug":"utf-8","permalink":"https://dengchuncui.github.io/tags/utf-8/"},{"name":"IO","slug":"IO","permalink":"https://dengchuncui.github.io/tags/IO/"}]}